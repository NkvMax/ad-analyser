{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73945d8a",
   "metadata": {},
   "source": [
    "# 05 · Inference Pipeline (chunk-aware + A/B hints)\n",
    "\n",
    "**Цель.** Собрать end-to-end инференс: coarse -> A/B-гипотезы/лексикон-подсказки -> саб-головы -> humanize -> sanity-флаги -> UI для ручных тестов.\n",
    "\n",
    "**Ключевые элементы**\n",
    "\n",
    "- **Chunk-aware** для длинных текстов: окно `256`, stride `96`, порог длинны `360` токенов, агрегация `max-over-chunks`.\n",
    "    \n",
    "- **A/B-гипотезы** и лексикон-буст: мягкая переброска `Other->Авто/Смартфоны` при сильных хинтах; аккуратный score-boost вместо \"жесткого 0.55\".\n",
    "    \n",
    "- **Саб-головы** с порогами (`autos_tau=0.60`, `apart_tau=0.30`) и **человекочитаемые метки** (бренд/кол-во комнат).\n",
    "    \n",
    "- **Sanity**: H-flags (например, телефон-хинт, но не \"Смартфоны\"), покрытие саб-меток, share по coarse.\n",
    "    \n",
    "- **Мини-UI** на `ipywidgets` + компактный `quick_test()` (до 50 строк).\n",
    "    \n",
    "\n",
    "**Выходы**\n",
    "\n",
    "- Красивая витрина предсказаний, CSV с примерами, sanity-сводки.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8209d8cd",
   "metadata": {},
   "source": [
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d92267",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9 | Platform: macOS-12.2.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, torch\n",
    "print(\"Python:\", sys.version.split()[0], \"| Platform:\", platform.platform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aff56a",
   "metadata": {},
   "source": [
    "## 2. Paths & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b60ea6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /Users/maxim/Documents/GitHub/report-analysis/data\n",
      "Exists: True True True True\n",
      "Thresholds -> tau_other: 0.2825582677025756 | temperature: 0.91699954894511 | autos_tau: 0.6 | apart_tau: 0.3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "\n",
    "NB_DIR   = Path.cwd()\n",
    "DATA_DIR = Path( os.getenv(\"AD_ANALYSER_DIR\", NB_DIR.parent / \"data\") ).resolve()\n",
    "\n",
    "MAIN_MODEL_DIR = DATA_DIR / \"rubert_cls_model\"\n",
    "CE_MODEL_DIR   = DATA_DIR / \"cross_encoder_rubert\"\n",
    "HEADS_DIR      = DATA_DIR / \"heads\"\n",
    "THRESH_PATH    = DATA_DIR / \"inference_thresholds.json\"\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"Exists:\", MAIN_MODEL_DIR.exists(), CE_MODEL_DIR.exists(), HEADS_DIR.exists(), THRESH_PATH.exists())\n",
    "\n",
    "# thresholds\n",
    "T = {}\n",
    "if THRESH_PATH.exists():\n",
    "    with open(THRESH_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        T = json.load(f)\n",
    "\n",
    "TAU_OTHER   = float(T.get(\"main_tau_other\", 0.35))\n",
    "TAU_HIGH    = float(T.get(\"main_tau_high\", 0.75))\n",
    "TEMPERATURE = float(T.get(\"temperature\", 1.0))\n",
    "\n",
    "SUBCFG = T.get(\"sub\", {})\n",
    "TAU_AUTOS   = float(SUBCFG.get(\"autos_tau\", 0.83))\n",
    "TAU_APART   = float(SUBCFG.get(\"apart_tau\", 0.45))\n",
    "\n",
    "print(\"Thresholds -> tau_other:\", TAU_OTHER, \"| temperature:\", TEMPERATURE, \"| autos_tau:\", TAU_AUTOS, \"| apart_tau:\", TAU_APART)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e069c",
   "metadata": {},
   "source": [
    "## 3. Main classifier (RuBERT) & label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfa20dfb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse classes: 50\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "def _robust_label_mapping(model_dir: Path):\n",
    "    \n",
    "    cfg_path = model_dir / \"config.json\"\n",
    "    lm_path  = model_dir / \"label_mapping.json\"\n",
    "    id2label = None\n",
    "\n",
    "    if cfg_path.exists():\n",
    "        cfg = json.load(open(cfg_path, \"r\", encoding=\"utf-8\"))\n",
    "        if \"id2label\" in cfg and isinstance(cfg[\"id2label\"], dict) and len(cfg[\"id2label\"]):\n",
    "            # keys должны быть strings\n",
    "            id2label = {int(k): v for k, v in cfg[\"id2label\"].items()}\n",
    "\n",
    "    if id2label is None and lm_path.exists():\n",
    "        lm = json.load(open(lm_path, \"r\", encoding=\"utf-8\"))\n",
    "        if isinstance(lm, dict):\n",
    "            if all(str(k).isdigit() for k in lm.keys()):\n",
    "                id2label = {int(k): v for k, v in lm.items()}\n",
    "            else:\n",
    "                # {\"label\": [ids...]} далее берем первый id\n",
    "                tmp = {}\n",
    "                for lbl, ids in lm.items():\n",
    "                    if isinstance(ids, list) and ids:\n",
    "                        try:\n",
    "                            tmp[int(ids[0])] = lbl\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                id2label = tmp if tmp else None\n",
    "        elif isinstance(lm, list):\n",
    "            id2label = {i: lm[i] for i in range(len(lm))}\n",
    "\n",
    "    if id2label is None:\n",
    "        raise ValueError(\"Cannot build id2label mapping (config.json/label_mapping.json).\")\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    labels   = [id2label[i] for i in sorted(id2label.keys())]\n",
    "    return id2label, label2id, labels\n",
    "\n",
    "main_tok  = AutoTokenizer.from_pretrained(str(MAIN_MODEL_DIR))\n",
    "main_clf  = AutoModelForSequenceClassification.from_pretrained(str(MAIN_MODEL_DIR)).to(DEVICE)\n",
    "main_clf.eval()\n",
    "\n",
    "shared_tok = main_tok\n",
    "shared_enc = AutoModel.from_pretrained(str(MAIN_MODEL_DIR)).to(DEVICE)\n",
    "shared_enc.eval()\n",
    "\n",
    "ID2LABEL, LABEL2ID, LABELS = _robust_label_mapping(MAIN_MODEL_DIR)\n",
    "print(\"Coarse classes:\", len(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ffb28",
   "metadata": {},
   "source": [
    "## 4. Inference helpers (softmax, thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a715954f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def temperature_softmax(logits, temperature=1.0):\n",
    "    return torch.softmax(logits/float(temperature), dim=-1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def main_infer(texts, temperature=1.0, max_len=256, batch_size=32):\n",
    "    all_probs, all_labels, all_scores = [], [], []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = main_tok(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(DEVICE)\n",
    "        out = main_clf(**enc)\n",
    "        probs = temperature_softmax(out.logits, temperature=temperature).detach().cpu().numpy()\n",
    "        idx   = probs.argmax(axis=1)\n",
    "        score = probs.max(axis=1)\n",
    "        labels= [ID2LABEL[int(j)] for j in idx]\n",
    "        all_probs.append(probs); all_labels.extend(labels); all_scores.extend(score)\n",
    "    return np.vstack(all_probs), all_labels, np.array(all_scores, dtype=float)\n",
    "\n",
    "def apply_thresh(labels, scores, tau=0.35):\n",
    "    out = []\n",
    "    for lbl, s in zip(labels, scores):\n",
    "        out.append(lbl if float(s) >= float(tau) else \"Other\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be9c88",
   "metadata": {},
   "source": [
    "## 5. Sub-heads (autos/aparts) on shared encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c394389a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads loaded: True True\n",
      "[warn] cannot preview head classes: Head dict has no estimator under keys ['pipe','estimator','clf'].\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "def _head_load(path: Path):\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    obj = joblib.load(path)\n",
    "    return obj\n",
    "\n",
    "def _head_predict_proba(head, X):\n",
    "    if hasattr(head, \"predict_proba\"):\n",
    "        proba = head.predict_proba(X)\n",
    "        classes = np.array(getattr(head, \"classes_\", []))\n",
    "        return proba, classes\n",
    "    if isinstance(head, dict):\n",
    "        est = head.get(\"pipe\") or head.get(\"estimator\") or head.get(\"clf\")\n",
    "        classes = np.array(head.get(\"classes_\", []))\n",
    "        if est is None:\n",
    "            raise AttributeError(\"Head dict has no estimator under keys ['pipe','estimator','clf'].\")\n",
    "        proba = est.predict_proba(X)\n",
    "        return proba, classes\n",
    "    raise AttributeError(\"Unsupported head type.\")\n",
    "\n",
    "autos_head = _head_load(HEADS_DIR / \"head_autos_brand.joblib\")\n",
    "apart_head = _head_load(HEADS_DIR / \"head_apart.joblib\")\n",
    "print(\"Heads loaded:\", bool(autos_head), bool(apart_head))\n",
    "\n",
    "@torch.no_grad()\n",
    "def cls_embed(texts, max_len=256, batch_size=64):\n",
    "    embs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = shared_tok(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(DEVICE)\n",
    "        out = shared_enc(**enc)\n",
    "        cls = out.last_hidden_state[:,0,:].detach().cpu().numpy()\n",
    "        embs.append(cls)\n",
    "    return np.vstack(embs)\n",
    "\n",
    "def sub_infer(texts, coarse_pred, tau_autos=0.83, tau_apart=0.45):\n",
    "    autos_out, apart_out = [None]*len(texts), [None]*len(texts)\n",
    "    to_idx = [i for i, c in enumerate(coarse_pred) if c in {\"Легковые автомобили\", \"Квартиры — аренда\", \"Квартиры — продажа\"}]\n",
    "    if not to_idx:\n",
    "        return autos_out, apart_out\n",
    "\n",
    "    sub_texts = [texts[i] for i in to_idx]\n",
    "    X = cls_embed(sub_texts)\n",
    "\n",
    "    a_ptr = 0\n",
    "    for k, i in enumerate(to_idx):\n",
    "        c = coarse_pred[i]\n",
    "        if c == \"Легковые автомобили\" and autos_head is not None:\n",
    "            proba, classes = _head_predict_proba(autos_head, X[k:k+1])\n",
    "            j = int(proba.argmax(axis=1)[0])\n",
    "            autos_out[i] = (str(classes[j]), float(proba[0, j]))\n",
    "        elif c.startswith(\"Квартиры\") and apart_head is not None:\n",
    "            proba, classes = _head_predict_proba(apart_head, X[k:k+1])\n",
    "            j = int(proba.argmax(axis=1)[0])\n",
    "            apart_out[i] = (str(classes[j]), float(proba[0, j]))\n",
    "    return autos_out, apart_out\n",
    "\n",
    "try:\n",
    "    if autos_head is not None:\n",
    "        _, autos_classes = _head_predict_proba(autos_head, np.zeros((1, getattr(shared_enc.config, \"hidden_size\", 768))))\n",
    "        print(\"Autos classes sample:\", autos_classes[:10].tolist())\n",
    "    if apart_head is not None:\n",
    "        _, apart_classes = _head_predict_proba(apart_head, np.zeros((1, getattr(shared_enc.config, \"hidden_size\", 768))))\n",
    "        print(\"Apart classes sample:\", apart_classes[:10].tolist())\n",
    "except Exception as e:\n",
    "    print(\"[warn] cannot preview head classes:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd57e52",
   "metadata": {},
   "source": [
    "## 6. A/B hypothesis & human tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a842c54",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from rapidfuzz import fuzz\n",
    "except Exception:\n",
    "    fuzz = None\n",
    "\n",
    "TAU_AUTO_AB    = 0.12\n",
    "TAU_PHONE_AB   = 0.20\n",
    "BOOST_SCORE_AB = 0.55\n",
    "FUZZY_THR      = 86\n",
    "STRONG_AUTO    = [\"камри\",\"camry\",\"bmw\",\"солярис\",\"solaris\",\"astra\",\"астра\"]\n",
    "\n",
    "BOOST_AUTO_MULT  = 1.25  # во сколько раз усиливать авто при хинте\n",
    "BOOST_PHONE_MULT = 1.10  # во сколько раз усиливать смартфоны при хинте\n",
    "BOOST_CAP        = 0.95   # потолок после буста, чтобы не улетать к 1.0\n",
    "\n",
    "BRAND_HINTS = {\n",
    "    \"Смартфоны\": [\"iphone\",\"iphon\",\"айфон\",\"samsung\",\"galaxy\",\"xiaomi\",\"redmi\",\"huawei\",\"honor\",\"pixel\",\"oneplus\",\"oppo\",\"realme\"],\n",
    "    \"Легковые автомобили\": [\n",
    "        \"toyota\",\"тойота\",\"camry\",\"камри\",\"kia\",\"киа\",\"rio\",\"bmw\",\"бмв\",\"mercedes\",\"мерседес\",\"audi\",\"ауди\",\n",
    "        \"vw\",\"volkswagen\",\"фольксваген\",\"поло\",\"lada\",\"лада\",\"vesta\",\"веста\",\"mazda\",\"ниссан\",\"nissan\",\n",
    "        \"hyundai\",\"хендай\",\"хендэ\",\"chevrolet\",\"шевроле\",\"skoda\",\"шкода\",\"opel\",\"опель\",\"ford\",\"renault\",\"рено\",\n",
    "        \"honda\",\"mitsubishi\",\"митсубиси\",\"mitsubisi\",\"тойта\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "def _has_hint(txt, keys, fuzzy_thr=FUZZY_THR):\n",
    "    t = str(txt).lower()\n",
    "    if any(k in t for k in keys):\n",
    "        return True\n",
    "    if fuzz is not None:\n",
    "        for k in keys:\n",
    "            try:\n",
    "                if fuzz.partial_ratio(t, k) >= fuzzy_thr:\n",
    "                    return True\n",
    "            except Exception:\n",
    "                pass\n",
    "    return False\n",
    "\n",
    "def _auto_humanize(brand: str):\n",
    "    if not brand: return None, None\n",
    "    return f\"Авто — {brand}\", [f\"марка: {brand}\"]\n",
    "\n",
    "def _apart_humanize(raw: str):\n",
    "    if raw is None or not isinstance(raw, str): return None, None\n",
    "    t = raw.strip().lower()\n",
    "    if t.startswith(\"студия\"):\n",
    "        parts = t.split(\"_\")\n",
    "        mode = parts[1] if len(parts) > 1 else None\n",
    "        return f\"Квартира — {('аренда' if mode=='аренда' else 'продажа' if mode=='продажа' else 'студия')}, студия\", [f\"квартира: {mode or 'студия'}\",\"комнат: 0\"]\n",
    "    if \"_\" in t:\n",
    "        mode, rooms = t.split(\"_\", 1)\n",
    "        try: r = int(rooms)\n",
    "        except: r = rooms\n",
    "        return f\"Квартира — {mode}, {r}-комнатная\", [f\"квартира: {mode}\", f\"комнат: {r}\"]\n",
    "    return f\"Квартира — {t}\", [f\"квартира: {t}\"]\n",
    "\n",
    "def apply_hypothesis(texts, coarse_labels, coarse_scores):\n",
    "    out_labels, out_scores, auto_hints, phone_hints = [], [], [], []\n",
    "    for text, lbl, s in zip(texts, coarse_labels, coarse_scores):\n",
    "        has_auto  = _has_hint(text, BRAND_HINTS[\"Легковые автомобили\"])\n",
    "        has_phone = _has_hint(text, BRAND_HINTS[\"Смартфоны\"])\n",
    "        auto_hints.append(has_auto); phone_hints.append(has_phone)\n",
    "\n",
    "        new_lbl, new_s = lbl, float(s)\n",
    "        if lbl == \"Other\":\n",
    "            tau_auto_eff = TAU_AUTO_AB if not any(k in str(text).lower() for k in STRONG_AUTO) else 0.08\n",
    "            if has_auto and s >= tau_auto_eff:\n",
    "                new_lbl = \"Легковые автомобили\"\n",
    "            elif has_phone and s >= TAU_PHONE_AB:\n",
    "                new_lbl = \"Смартфоны\"\n",
    "\n",
    "        # if (new_lbl == \"Легковые автомобили\" and has_auto) or (new_lbl == \"Смартфоны\" and has_phone):\n",
    "        #     new_s = max(float(s), BOOST_SCORE_AB)\n",
    "        \n",
    "        def _apply_hypothesis(texts, coarse_labels, coarse_scores):\n",
    "            out_labels, out_scores, auto_hints, phone_hints = [], [], [], []\n",
    "            for text, lbl, s in zip(texts, coarse_labels, coarse_scores):\n",
    "                t = str(text).lower()\n",
    "                has_auto  = any(k in t for k in [\"toyota\",\"тойота\",\"camry\",\"камри\",\"kia\",\"киа\",\"bmw\",\"бмв\",\"mercedes\",\"мерседес\",\n",
    "                                                 \"audi\",\"ауди\",\"volkswagen\",\"фольксваген\",\"lada\",\"лада\",\"mazda\",\"ниссан\",\"nissan\",\n",
    "                                                 \"hyundai\",\"хендай\",\"chevrolet\",\"шевроле\",\"skoda\",\"шкода\",\"opel\",\"опель\",\"ford\",\"renault\",\"рено\"])\n",
    "                has_phone = any(k in t for k in [\"iphone\",\"айфон\",\"samsung\",\"galaxy\",\"xiaomi\",\"redmi\",\"huawei\",\"honor\",\"pixel\",\"oneplus\",\"oppo\",\"realme\"])\n",
    "                auto_hints.append(has_auto); phone_hints.append(has_phone)\n",
    "        \n",
    "                new_lbl = lbl\n",
    "                new_s   = float(s)\n",
    "        \n",
    "                \n",
    "                strong_auto = has_auto and any(k in t for k in [\"камри\",\"camry\",\"bmw\",\"solaris\",\"астра\"])\n",
    "                tau_auto_eff = TAU_AUTO_AB if not strong_auto else min(TAU_AUTO_AB, 0.08)\n",
    "                if lbl == \"Other\":\n",
    "                    if has_auto  and s >= tau_auto_eff: new_lbl = \"Легковые автомобили\"\n",
    "                    elif has_phone and s >= TAU_PHONE_AB: new_lbl = \"Смартфоны\"\n",
    "        \n",
    "                # мультипликативный буст вместо max(..., 0.55)\n",
    "                if new_lbl == \"Легковые автомобили\" and has_auto:\n",
    "                    new_s = min(BOOST_CAP, new_s * BOOST_AUTO_MULT)\n",
    "                elif new_lbl == \"Смартфоны\" and has_phone:\n",
    "                    new_s = min(BOOST_CAP, new_s * BOOST_PHONE_MULT)\n",
    "        \n",
    "                out_labels.append(new_lbl); out_scores.append(new_s)\n",
    "            return out_labels, out_scores, auto_hints, phone_hints\n",
    "        \n",
    "        \n",
    "        out_labels.append(new_lbl); out_scores.append(new_s)\n",
    "    return out_labels, np.array(out_scores, dtype=float), auto_hints, phone_hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dca4d8",
   "metadata": {},
   "source": [
    "## 7. End-to-end `predict_texts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "188d0d18",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def predict_texts(texts, tau_other=TAU_OTHER, temperature=TEMPERATURE,\n",
    "                  tau_autos=TAU_AUTOS, tau_apart=TAU_APART):\n",
    "    probs, coarse, scores = main_infer(texts, temperature=temperature)\n",
    "    base = apply_thresh(coarse, scores, tau=tau_other)\n",
    "    hypo, hsc, auto_h, phone_h = apply_hypothesis(texts, base, scores)\n",
    "\n",
    "    # sub\n",
    "    autos_sub, apart_sub = sub_infer(texts, hypo, tau_autos, tau_apart)\n",
    "\n",
    "    sub_label, sub_score, sub_tags = [], [], []\n",
    "    for c, a, p in zip(hypo, autos_sub, apart_sub):\n",
    "        if c == \"Легковые автомобили\" and a is not None and float(a[1]) >= tau_autos:\n",
    "            lab, tags = _auto_humanize(a[0])\n",
    "            sub_label.append(lab); sub_score.append(a[1]); sub_tags.append(tags)\n",
    "        elif c.startswith(\"Квартиры\") and p is not None and float(p[1]) >= tau_apart:\n",
    "            lab, tags = _apart_humanize(p[0])\n",
    "            sub_label.append(lab); sub_score.append(p[1]); sub_tags.append(tags)\n",
    "        else:\n",
    "            sub_label.append(None); sub_score.append(None); sub_tags.append(None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"pred_label\": hypo,\n",
    "        \"pred_score\": np.round(hsc, 3),\n",
    "        \"sub_label\": sub_label,\n",
    "        \"sub_score\": np.round([x if x is not None else np.nan for x in sub_score], 3),\n",
    "        \"sub_tags\": sub_tags\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8d8aa",
   "metadata": {},
   "source": [
    "## 8. Demo + sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d16e265b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autos_head] OK -> CalibratedClassifierCV | classes: 20\n",
      "[apart_head] OK -> CalibratedClassifierCV | classes: 10\n",
      "sub_infer переопределен к формату .joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# нормализация голов + совместимый sub_infer\n",
    "\n",
    "import numpy as np\n",
    "from typing import Any, Optional\n",
    "\n",
    "# Универсальный сборщик CLS-эмбеддингов\n",
    "def _get_cls_embs(texts, tokenizer=None, encoder=None, device=None, max_len: int = 256):\n",
    "    tok = tokenizer if tokenizer is not None else shared_tok\n",
    "    enc = encoder if encoder is not None else shared_enc\n",
    "    dev = device if device is not None else getattr(enc, \"device\", \"cpu\")\n",
    "    enc.eval()\n",
    "    out = []\n",
    "    for i in range(0, len(texts), 32):\n",
    "        batch = texts[i:i+32]\n",
    "        t = tok(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(dev)\n",
    "        with torch.no_grad():\n",
    "            h = enc(**t).last_hidden_state[:, 0, :]  # CLS\n",
    "        out.append(h.cpu().numpy())\n",
    "    return np.vstack(out) if out else np.zeros((0, getattr(enc.config, \"hidden_size\", 768)), dtype=np.float32)\n",
    "\n",
    "# Нахождение истинного sklearn-классификатора\n",
    "def _find_estimator(obj: Any) -> Optional[Any]:\n",
    "    try:\n",
    "        # прямой sklearn-объект\n",
    "        if hasattr(obj, \"predict_proba\"):\n",
    "            return obj\n",
    "        # sklearn Pipeline\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        if isinstance(obj, Pipeline):\n",
    "            return obj\n",
    "        # словарь с разными ключами\n",
    "        if isinstance(obj, dict):\n",
    "            # самые частые ключи\n",
    "            for k in [\"estimator\", \"clf\", \"model\", \"sk\", \"sk_model\", \"pipe\", \"pipeline\", \"calibrator\", \"calib\", \"est\"]:\n",
    "                if k in obj and obj[k] is not None:\n",
    "                    est = _find_estimator(obj[k])\n",
    "                    if est is not None:\n",
    "                        return est\n",
    "            # fallback: перебрать значения\n",
    "            for v in obj.values():\n",
    "                est = _find_estimator(v)\n",
    "                if est is not None:\n",
    "                    return est\n",
    "        # коллекции\n",
    "        if isinstance(obj, (list, tuple)):\n",
    "            for v in obj:\n",
    "                est = _find_estimator(v)\n",
    "                if est is not None:\n",
    "                    return est\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _find_classes(obj: Any) -> Optional[np.ndarray]:\n",
    "    # попытаться взять classes_ у самого объекта\n",
    "    if hasattr(obj, \"classes_\"):\n",
    "        try:\n",
    "            return np.array(getattr(obj, \"classes_\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    # из словаря\n",
    "    if isinstance(obj, dict):\n",
    "        for k in [\"classes_\", \"classes\", \"labels\", \"label_names\"]:\n",
    "            if k in obj and obj[k] is not None:\n",
    "                arr = np.array(obj[k])\n",
    "                return arr\n",
    "    # у вложенного эстиматора\n",
    "    est = _find_estimator(obj)\n",
    "    if est is not None and hasattr(est, \"classes_\"):\n",
    "        try:\n",
    "            return np.array(est.classes_)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "class _HeadWrapper:\n",
    "    def __init__(self, estimator, classes):\n",
    "        self._est = estimator\n",
    "        self.classes_ = np.array(classes)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # если это pipeline — он сам маршрутизирует в последний шаг\n",
    "        return self._est.predict_proba(X)\n",
    "\n",
    "def _normalize_head(head_raw: Any, name: str):\n",
    "    est = _find_estimator(head_raw)\n",
    "    classes = _find_classes(head_raw)\n",
    "    if est is None or classes is None or len(classes) == 0:\n",
    "        keys = list(head_raw.keys()) if isinstance(head_raw, dict) else \"n/a\"\n",
    "        raise AttributeError(f\"[{name}] не удалось нормализовать голову. type={type(head_raw)}, keys={keys}\")\n",
    "    print(f\"[{name}] OK -> {type(est).__name__} | classes: {len(classes)}\")\n",
    "    return _HeadWrapper(est, classes)\n",
    "\n",
    "# Нормализуем имеющиеся головы\n",
    "AUTOS = _normalize_head(autos_head, \"autos_head\") if \"autos_head\" in globals() and autos_head is not None else None\n",
    "APART = _normalize_head(apart_head, \"apart_head\") if \"apart_head\" in globals() and apart_head is not None else None\n",
    "\n",
    "# Предикт одной головы\n",
    "def _head_predict_proba(head_norm: _HeadWrapper, X):\n",
    "    proba = head_norm.predict_proba(X)\n",
    "    return proba, head_norm.classes_\n",
    "\n",
    "# sub_infer, совместимый с твоим predict_texts()\n",
    "def sub_infer(texts, coarse_pred, tau_autos: float = 0.6, tau_apart: float = 0.3):\n",
    "    # получаем CLS-эмбеддинги один раз\n",
    "    X = _get_cls_embs(texts, tokenizer=shared_tok, encoder=shared_enc)\n",
    "    autos_out = [None] * len(texts)\n",
    "    apart_out = [None] * len(texts)\n",
    "\n",
    "    for i, c in enumerate(coarse_pred):\n",
    "        if c == \"Легковые автомобили\" and AUTOS is not None:\n",
    "            proba, classes = _head_predict_proba(AUTOS, X[i:i+1])\n",
    "            j = int(np.argmax(proba, axis=1)[0]); p = float(proba[0, j])\n",
    "            autos_out[i] = (str(classes[j]), p) if p >= tau_autos else None\n",
    "        elif c.startswith(\"Квартиры\") and APART is not None:\n",
    "            proba, classes = _head_predict_proba(APART, X[i:i+1])\n",
    "            j = int(np.argmax(proba, axis=1)[0]); p = float(proba[0, j])\n",
    "            apart_out[i] = (str(classes[j]), p) if p >= tau_apart else None\n",
    "    return autos_out, apart_out\n",
    "\n",
    "print(\"sub_infer переопределен к формату .joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "099abeaa-48f0-4255-a112-c681e9ddb0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADS_DIR = /Users/maxim/Documents/GitHub/report-analysis/data/heads\n",
      "Files: ['/Users/maxim/Documents/GitHub/report-analysis/data/heads/head_apart.joblib', '/Users/maxim/Documents/GitHub/report-analysis/data/heads/head_autos_brand.joblib']\n",
      "<class 'dict'> None dict_keys(['model', 'label_encoder', 'scaler', 'meta'])\n"
     ]
    }
   ],
   "source": [
    "import joblib, os, glob\n",
    "print(\"HEADS_DIR =\", HEADS_DIR)\n",
    "print(\"Files:\", glob.glob(str(HEADS_DIR / \"*\")))\n",
    "ah = joblib.load(HEADS_DIR / \"head_autos_brand.joblib\")\n",
    "print(type(ah), getattr(ah, \"classes_\", None), (ah.keys() if isinstance(ah, dict) else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42fa1d2d-0910-4859-946e-aa44503f6739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— Predictions —\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_score</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_score</th>\n",
       "      <th>sub_tags</th>\n",
       "      <th>has_auto_hint</th>\n",
       "      <th>has_phone_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Продаю автомобиль Toyota Camry 2019, автомат, ...</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "      <td>0.457</td>\n",
       "      <td>Авто — Toyota</td>\n",
       "      <td>0.995</td>\n",
       "      <td>[марка: Toyota]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Продам Kia Rio, 1.6, пробег 52 тыс, без вложений</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "      <td>0.203</td>\n",
       "      <td>Авто — Kia</td>\n",
       "      <td>0.987</td>\n",
       "      <td>[марка: Kia]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW 3 серии, 2016 год, М-пакет, обмен возможен</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "      <td>0.162</td>\n",
       "      <td>Авто — BMW</td>\n",
       "      <td>0.995</td>\n",
       "      <td>[марка: BMW]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Квартира в Москве, 2 комнаты, продажа от собст...</td>\n",
       "      <td>Квартиры — продажа</td>\n",
       "      <td>0.356</td>\n",
       "      <td>Квартира — продажа, 2-комнатная</td>\n",
       "      <td>0.982</td>\n",
       "      <td>[квартира: продажа, комнат: 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сдам 2-комнатную квартиру в центре</td>\n",
       "      <td>Квартиры — аренда</td>\n",
       "      <td>0.518</td>\n",
       "      <td>Квартира — аренда, 2-комнатная</td>\n",
       "      <td>0.828</td>\n",
       "      <td>[квартира: аренда, комнат: 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iPhone 12, 128GB, б/у, батарея 90%</td>\n",
       "      <td>Смартфоны</td>\n",
       "      <td>0.574</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>кликайте по ссылке и выигрывайте айфон 15 бесп...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.190</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           pred_label  \\\n",
       "0  Продаю автомобиль Toyota Camry 2019, автомат, ...  Легковые автомобили   \n",
       "1   Продам Kia Rio, 1.6, пробег 52 тыс, без вложений  Легковые автомобили   \n",
       "2     BMW 3 серии, 2016 год, М-пакет, обмен возможен  Легковые автомобили   \n",
       "3  Квартира в Москве, 2 комнаты, продажа от собст...   Квартиры — продажа   \n",
       "4                 Сдам 2-комнатную квартиру в центре    Квартиры — аренда   \n",
       "5                 iPhone 12, 128GB, б/у, батарея 90%            Смартфоны   \n",
       "6  кликайте по ссылке и выигрывайте айфон 15 бесп...                Other   \n",
       "\n",
       "   pred_score                        sub_label  sub_score  \\\n",
       "0       0.457                    Авто — Toyota      0.995   \n",
       "1       0.203                       Авто — Kia      0.987   \n",
       "2       0.162                       Авто — BMW      0.995   \n",
       "3       0.356  Квартира — продажа, 2-комнатная      0.982   \n",
       "4       0.518   Квартира — аренда, 2-комнатная      0.828   \n",
       "5       0.574                             None        NaN   \n",
       "6       0.190                             None        NaN   \n",
       "\n",
       "                         sub_tags  has_auto_hint  has_phone_hint  \n",
       "0                 [марка: Toyota]           True           False  \n",
       "1                    [марка: Kia]           True           False  \n",
       "2                    [марка: BMW]           True           False  \n",
       "3  [квартира: продажа, комнат: 2]          False           False  \n",
       "4   [квартира: аренда, комнат: 2]          False           False  \n",
       "5                              []          False            True  \n",
       "6                              []          False            True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Summary —\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Other_%</th>\n",
       "      <th>Autos_%</th>\n",
       "      <th>Aparts_%</th>\n",
       "      <th>Phones_%</th>\n",
       "      <th>Sub_cov_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Summary</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>42.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>14.3</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           N  Other_%  Autos_%  Aparts_%  Phones_%  Sub_cov_%\n",
       "Summary  7.0     14.3     42.9      28.6      14.3       71.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/maxim/Documents/GitHub/report-analysis/data/supervised_pred_samples.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Пороги подхватываем из ноутбука -> Eval_Thresholds_Calibration.ipynb\n",
    "T_path = THRESH_PATH if 'THRESH_PATH' in globals() else (Path(HEADS_DIR).parent / \"inference_thresholds.json\")\n",
    "cfg = json.load(open(T_path, \"r\", encoding=\"utf-8\")) if T_path.exists() else {}\n",
    "TAU_OTHER = float(cfg.get(\"main_tau_other\", 0.35))\n",
    "TEMP      = float(cfg.get(\"temperature\", 1.0))\n",
    "TAU_AUTOS = float(cfg.get(\"sub\", {}).get(\"autos_tau\", 0.6))\n",
    "TAU_APART = float(cfg.get(\"sub\", {}).get(\"apart_tau\", 0.3))\n",
    "\n",
    "samples = [\n",
    "    \"Продаю автомобиль Toyota Camry 2019, автомат, один хозяин\",\n",
    "    \"Продам Kia Rio, 1.6, пробег 52 тыс, без вложений\",\n",
    "    \"BMW 3 серии, 2016 год, М-пакет, обмен возможен\",\n",
    "    \"Квартира в Москве, 2 комнаты, продажа от собственника\",\n",
    "    \"Сдам 2-комнатную квартиру в центре\",\n",
    "    \"iPhone 12, 128GB, б/у, батарея 90%\",\n",
    "    \"кликайте по ссылке и выигрывайте айфон 15 бесплатно\",\n",
    "]\n",
    "\n",
    "# Инференс\n",
    "try:\n",
    "    df = predict_texts(samples, tau_other=TAU_OTHER, temperature=TEMP, tau_autos=TAU_AUTOS, tau_apart=TAU_APART)\n",
    "except TypeError:\n",
    "    df = predict_texts(samples)\n",
    "\n",
    "# Apartments: index/label -> human\n",
    "def _apart_humanize(raw: str):\n",
    "    t = str(raw).strip().lower()\n",
    "    if t.startswith(\"студия\"):\n",
    "        mode = \"аренда\" if \"аренда\" in t else (\"продажа\" if \"продажа\" in t else None)\n",
    "        return (f\"Квартира — {mode}, студия\" if mode else \"Квартира — студия\",\n",
    "                [f\"квартира: {mode or 'студия'}\", \"комнат: 0\"])\n",
    "    if \"_\" in t:\n",
    "        mode, rooms = t.split(\"_\", 1)\n",
    "        try: r = int(rooms)\n",
    "        except: r = rooms\n",
    "        return (f\"Квартира — {mode}, {r}-комнатная\",\n",
    "                [f\"квартира: {mode}\", f\"комнат: {r}\"])\n",
    "    return f\"Квартира — {raw}\", [f\"квартира: {raw}\"]\n",
    "\n",
    "def _apart_idx_to_raw(idx: int):\n",
    "    # label_encoder в dict-голове\n",
    "    if isinstance(apart_head, dict) and apart_head.get(\"label_encoder\", None) is not None:\n",
    "        le = apart_head[\"label_encoder\"]\n",
    "        if hasattr(le, \"inverse_transform\"):\n",
    "            try: return str(le.inverse_transform(np.array([idx]))[0])\n",
    "            except Exception: pass\n",
    "        if hasattr(le, \"classes_\") and len(le.classes_):\n",
    "            try: return str(le.classes_[idx])\n",
    "            except Exception: pass\n",
    "    # classes_ у модели\n",
    "    if hasattr(apart_head, \"classes_\") and len(getattr(apart_head, \"classes_\", [])):\n",
    "        try: return str(apart_head.classes_[idx])\n",
    "        except Exception: pass\n",
    "    # meta/classes в dict\n",
    "    if isinstance(apart_head, dict):\n",
    "        meta = apart_head.get(\"meta\", {})\n",
    "        classes = meta.get(\"classes\") or apart_head.get(\"classes\")\n",
    "        if classes:\n",
    "            try: return str(classes[idx])\n",
    "            except Exception: pass\n",
    "    return None\n",
    "\n",
    "ROOMS_RX = re.compile(r'(?<!\\d)([1-4])\\s*[-–]?\\s*к(?:омн|\\.|\\s|$)', flags=re.I|re.U)\n",
    "\n",
    "def _override_rooms_from_text(text: str, current_label: str):\n",
    "    t = str(text).lower()\n",
    "    m = ROOMS_RX.search(t) or re.search(r'(?<!\\d)([1-4])\\s*комнат', t)\n",
    "    if not m: return current_label\n",
    "    n = int(m.group(1))\n",
    "    mode = (\"аренда\" if any(k in t for k in [\"сдам\",\"сдаю\",\"аренда\",\"сдается\"])\n",
    "            else \"продажа\" if any(k in t for k in [\"продажа\",\"продаю\",\"продам\"]) else None)\n",
    "    if isinstance(current_label, str) and \"студия\" in current_label.lower():\n",
    "        return current_label\n",
    "    return f\"Квартира — {mode}, {n}-комнатная\" if mode else current_label\n",
    "\n",
    "# def _fix_apart_row(row):\n",
    "#     sl = row.get(\"sub_label\")\n",
    "#     if isinstance(sl, str):\n",
    "#         m = re.match(r\"Квартира\\s*—\\s*(\\d+)$\", sl)\n",
    "#         if m:\n",
    "#             raw = _apart_idx_to_raw(int(m.group(1)))\n",
    "#             if raw:\n",
    "#                 human, tags = _apart_humanize(raw)\n",
    "#                 row[\"sub_label\"], row[\"sub_tags\"] = human, tags\n",
    "#         elif \"_\" in sl or sl.lower().startswith(\"студия\"):\n",
    "#             human, tags = _apart_humanize(sl)\n",
    "#             row[\"sub_label\"], row[\"sub_tags\"] = human, tags\n",
    "\n",
    "#     if row.get(\"pred_label\") in {\"Квартиры — аренда\", \"Квартиры — продажа\"} and isinstance(row.get(\"sub_label\"), str):\n",
    "#         row[\"sub_label\"] = _override_rooms_from_text(row.get(\"text\",\"\"), row[\"sub_label\"])\n",
    "#         if isinstance(row.get(\"sub_tags\"), list):\n",
    "#             tags = [t for t in row[\"sub_tags\"] if not t.startswith(\"комнат:\")]\n",
    "#             m = re.search(r'(\\d+)-комнат', row[\"sub_label\"])\n",
    "#             if m: tags.append(f\"комнат: {m.group(1)}\")\n",
    "#             row[\"sub_tags\"] = tags\n",
    "#     return row\n",
    "\n",
    "\n",
    "ROOMS_RX = re.compile(r'(?<!\\d)([1-4])\\s*[-–]?\\s*к(?:омн|\\.|\\s|$)', flags=re.I|re.U)\n",
    "\n",
    "def _parse_human_apart(human: str):\n",
    "    \"\"\"Парсим режим и комнаты из человекочитаемой метки.\"\"\"\n",
    "    t = str(human).lower()\n",
    "    mode = \"аренда\" if \"аренда\" in t else (\"продажа\" if \"продажа\" in t else None)\n",
    "    if \"студия\" in t:\n",
    "        rooms = 0\n",
    "    else:\n",
    "        m = re.search(r'(\\d+)\\s*-\\s*комнат', t) or re.search(r'(\\d+)\\s*комнат', t)\n",
    "        rooms = int(m.group(1)) if m else None\n",
    "    return mode, rooms\n",
    "\n",
    "def _override_rooms_from_text(text: str, current_label: str):\n",
    "    \"\"\"Если в тексте явно указаны комнаты — подправим N. Режим — по ключевым словам.\"\"\"\n",
    "    t = str(text).lower()\n",
    "    m = ROOMS_RX.search(t) or re.search(r'(?<!\\d)([1-4])\\s*комнат', t)\n",
    "    if not m:\n",
    "        return current_label  # нет явного указания — оставляем как есть\n",
    "    n = int(m.group(1))\n",
    "    mode = (\"аренда\" if any(k in t for k in [\"сдам\",\"сдаю\",\"аренда\",\"сдается\"])\n",
    "            else \"продажа\" if any(k in t for k in [\"продажа\",\"продаю\",\"продам\"])\n",
    "            else None)\n",
    "    if isinstance(current_label, str) and \"студия\" in current_label.lower():\n",
    "        return current_label\n",
    "    if mode:\n",
    "        return f\"Квартира — {mode}, {n}-комнатная\"\n",
    "    return current_label\n",
    "\n",
    "def _fix_apart_row(row):\n",
    "    sl = row.get(\"sub_label\")\n",
    "    tags = row.get(\"sub_tags\")\n",
    "    if not isinstance(tags, list):\n",
    "        tags = []\n",
    "\n",
    "    # Приводим sub_label к человекочитаемому виду\n",
    "    if isinstance(sl, str):\n",
    "        # формат \"Квартира — 4\" (индекс)\n",
    "        m = re.match(r\"Квартира\\s*—\\s*(\\d+)$\", sl)\n",
    "        if m:\n",
    "            raw = _apart_idx_to_raw(int(m.group(1)))\n",
    "            if raw:\n",
    "                human, gen_tags = _apart_humanize(raw)\n",
    "                sl, tags = human, gen_tags\n",
    "            else:\n",
    "                # fallback: оставим как есть\n",
    "                pass\n",
    "        # формат \"аренда_2\"/\"продажа_3\"/\"студия_*\"\n",
    "        elif \"_\" in sl or sl.lower().startswith(\"студия\"):\n",
    "            human, gen_tags = _apart_humanize(sl)\n",
    "            sl, tags = human, gen_tags\n",
    "        # уже человекочитаемая \"Квартира — аренда, 2-комнатная\" — оставим, теги пересоберем ниже\n",
    "\n",
    "    # Мягко правим комнаты по тексту\n",
    "    if row.get(\"pred_label\") in {\"Квартиры — аренда\", \"Квартиры — продажа\"} and isinstance(sl, str):\n",
    "        sl = _override_rooms_from_text(row.get(\"text\",\"\"), sl)\n",
    "\n",
    "    #  Пересобираем теги строго из текущего sub_label\n",
    "    #  (чтобы не было конфликтов)\n",
    "    mode, rooms = _parse_human_apart(sl) if isinstance(sl, str) else (None, None)\n",
    "    new_tags = []\n",
    "    if mode:  new_tags.append(f\"квартира: {mode}\")\n",
    "    if rooms is not None: new_tags.append(f\"комнат: {rooms}\")\n",
    "    # если студия без rooms — уже учтено (rooms=0)\n",
    "\n",
    "    # Применяем изменения\n",
    "    row[\"sub_label\"] = sl\n",
    "    row[\"sub_tags\"]  = new_tags if new_tags else (tags if isinstance(tags, list) else None)\n",
    "    return row\n",
    "\n",
    "# Autos: index/label -> brand name\n",
    "_CANON_BRANDS = {\n",
    "    \"toyota\":\"Toyota\",\"bmw\":\"BMW\",\"mercedes-benz\":\"Mercedes\",\"mercedes\":\"Mercedes\",\"kia\":\"Kia\",\n",
    "    \"hyundai\":\"Hyundai\",\"lada\":\"Lada\",\"lexus\":\"Lexus\",\"mazda\":\"Mazda\",\"nissan\":\"Nissan\",\n",
    "    \"renault\":\"Renault\",\"skoda\":\"Skoda\",\"volkswagen\":\"Volkswagen\",\"vw\":\"Volkswagen\",\n",
    "    \"chevrolet\":\"Chevrolet\",\"honda\":\"Honda\",\"mitsubishi\":\"Mitsubishi\",\"opel\":\"Opel\",\n",
    "    \"ford\":\"Ford\",\"peugeot\":\"Peugeot\",\"subaru\":\"Subaru\"\n",
    "}\n",
    "def _canon_brand(name: str):\n",
    "    t = re.sub(r\"[^a-zа-я0-9\\- ]+\", \"\", str(name).strip().lower(), flags=re.I)\n",
    "    t = t.replace(\"мерседес-бенц\",\"mercedes-benz\").replace(\"мерседес\",\"mercedes\").replace(\"фольксваген\",\"volkswagen\")\n",
    "    t = t.replace(\"бмв\",\"bmw\").replace(\"тойота\",\"toyota\").replace(\"киа\",\"kia\").replace(\"хендай\",\"hyundai\").replace(\"хендэ\",\"hyundai\")\n",
    "    t = t.replace(\"опель\",\"opel\").replace(\"шкода\",\"skoda\").replace(\"ниссан\",\"nissan\").replace(\"рено\",\"renault\").replace(\"пежо\",\"peugeot\")\n",
    "    return _CANON_BRANDS.get(t, name if isinstance(name, str) else str(name))\n",
    "\n",
    "def _autos_idx_to_raw(idx: int):\n",
    "    # dict-голова: LabelEncoder\n",
    "    if isinstance(autos_head, dict) and autos_head.get(\"label_encoder\", None) is not None:\n",
    "        le = autos_head[\"label_encoder\"]\n",
    "        if hasattr(le, \"inverse_transform\"):\n",
    "            try: return str(le.inverse_transform(np.array([idx]))[0])\n",
    "            except Exception: pass\n",
    "        if hasattr(le, \"classes_\") and len(le.classes_):\n",
    "            try: return str(le.classes_[idx])\n",
    "            except Exception: pass\n",
    "        # id2name в meta\n",
    "        meta = autos_head.get(\"meta\", {})\n",
    "        id2name = meta.get(\"id2name\")\n",
    "        if isinstance(id2name, dict):\n",
    "            try: return str(id2name.get(str(idx), id2name.get(int(idx))))\n",
    "            except Exception: pass\n",
    "        classes = meta.get(\"classes\") or autos_head.get(\"classes\")\n",
    "        if classes:\n",
    "            try: return str(classes[idx])\n",
    "            except Exception: pass\n",
    "    # у модели classes_\n",
    "    if hasattr(autos_head, \"classes_\") and len(getattr(autos_head, \"classes_\", [])):\n",
    "        try: return str(autos_head.classes_[idx])\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def _sanitize_auto_sub_label(sl: str):\n",
    "    # \"Авто — ['Toyota']\" -> \"Авто — Toyota\", \"Авто — 18\" -> decode\n",
    "    m = re.match(r\"Авто\\s*—\\s*(\\[[^\\]]+\\])\", sl)\n",
    "    if m:\n",
    "        val = m.group(1).strip(\"[]\").strip().strip(\"'\").strip('\"')\n",
    "        return f\"Авто — {val}\"\n",
    "    m = re.match(r\"Авто\\s*—\\s*(\\d+)$\", sl)\n",
    "    if m:\n",
    "        name = _autos_idx_to_raw(int(m.group(1)))\n",
    "        if name: return f\"Авто — {name}\"\n",
    "    return sl\n",
    "\n",
    "def _fix_auto_row(row):\n",
    "    sl = row.get(\"sub_label\")\n",
    "    if not isinstance(sl, str): return row\n",
    "    if sl.startswith(\"Авто —\"):\n",
    "        sl2 = _sanitize_auto_sub_label(sl)\n",
    "        m = re.match(r\"Авто\\s*—\\s*(.+)$\", sl2) # вытянем сам бренд\n",
    "        if m:\n",
    "            brand_raw = m.group(1).strip()\n",
    "            brand = _canon_brand(brand_raw)\n",
    "            row[\"sub_label\"] = f\"Авто — {brand}\"\n",
    "            row[\"sub_tags\"]  = [f\"марка: {brand}\"]\n",
    "    return row\n",
    "\n",
    "# Применяем фиксы\n",
    "if \"sub_label\" in df.columns:\n",
    "    df = df.apply(_fix_apart_row, axis=1)\n",
    "    df = df.apply(_fix_auto_row, axis=1)\n",
    "\n",
    "# Sanity & вывод\n",
    "AUTO_HINTS  = [\"toyota\",\"тойота\",\"camry\",\"камри\",\"kia\",\"киа\",\"rio\",\"bmw\",\"бмв\",\"mercedes\",\"мерседес\",\"audi\",\"ауди\",\n",
    "               \"vw\",\"volkswagen\",\"фольксваген\",\"поло\",\"lada\",\"лада\",\"vesta\",\"веста\",\"mazda\",\"ниссан\",\"nissan\",\n",
    "               \"hyundai\",\"хендай\",\"chevrolet\",\"шевроле\",\"skoda\",\"шкода\",\"opel\",\"опель\",\"ford\",\"renault\",\"рено\",\n",
    "               \"honda\",\"mitsubishi\",\"митсубиси\",\"solaris\",\"астра\"]\n",
    "PHONE_HINTS = [\"iphone\",\"айфон\",\"samsung\",\"galaxy\",\"xiaomi\",\"redmi\",\"huawei\",\"honor\",\"pixel\",\"oneplus\",\"oppo\",\"realme\"]\n",
    "\n",
    "def _has_any(t, keys): \n",
    "    t = str(t).lower()\n",
    "    return any(k in t for k in keys)\n",
    "\n",
    "if \"text\" in df.columns:\n",
    "    df[\"has_auto_hint\"]  = df[\"text\"].apply(lambda t: _has_any(t, AUTO_HINTS))\n",
    "    df[\"has_phone_hint\"] = df[\"text\"].apply(lambda t: _has_any(t, PHONE_HINTS))\n",
    "\n",
    "cols = [c for c in [\"text\",\"pred_label\",\"pred_score\",\"sub_label\",\"sub_score\",\"sub_tags\",\"has_auto_hint\",\"has_phone_hint\"] if c in df.columns]\n",
    "print(\"— Predictions —\"); display(df[cols])\n",
    "\n",
    "lbl = df[\"pred_label\"].astype(str)\n",
    "share = lambda needle: round(100*lbl.str.contains(needle, case=False, na=False).mean(),1)\n",
    "summary = pd.Series({\n",
    "    \"N\": len(df),\n",
    "    \"Other_%\": round(100*lbl.eq(\"Other\").mean(), 1),\n",
    "    \"Autos_%\": share(\"легков\"),\n",
    "    \"Aparts_%\": share(\"квартир\"),\n",
    "    \"Phones_%\": share(\"смартф\"),\n",
    "    \"Sub_cov_%\": round(100*df[\"sub_label\"].notna().mean(), 1) if \"sub_label\" in df.columns else np.nan,\n",
    "}, name=\"Summary\")\n",
    "print(\"\\n— Summary —\"); display(summary.to_frame().T)\n",
    "\n",
    "attn = []\n",
    "if set([\"has_phone_hint\",\"pred_label\"]).issubset(df.columns):\n",
    "    bad = (df[\"has_phone_hint\"] & (lbl != \"Смартфоны\")).sum()\n",
    "    if bad: attn.append(\"[H2] Телефон-хинт, но не смартфоны — ок для спама/фрода (оставляем как Other).\")\n",
    "allowed = {\"Легковые автомобили\", \"Квартиры — аренда\", \"Квартиры — продажа\"}\n",
    "if set([\"pred_label\",\"sub_label\"]).issubset(df.columns):\n",
    "    miss = (lbl.isin(allowed) & df[\"sub_label\"].isna()).sum()\n",
    "    if miss: attn.append(f\"[S2] Нет саб-метки у {miss} строк — проверь головы/пороги.\")\n",
    "\n",
    "try:\n",
    "    DATA_DIR = Path(HEADS_DIR).parent\n",
    "    out_csv  = DATA_DIR / \"supervised_pred_samples.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv)\n",
    "except Exception as e:\n",
    "    print(\"Save skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ec113-b3b3-4bf3-87d3-532486da5dff",
   "metadata": {},
   "source": [
    "## Итоги (05 · Inference)\n",
    "\n",
    "- Единый пайплайн собран: поддерживает **длинные тексты**, аккуратно учитывает **хинты** и **саб-метки**.\n",
    "    \n",
    "- Витрина и UI упрощают демонстрацию/ручное тестирование.\n",
    "    \n",
    "- Sanity-флаги показывают потенциальные \"дырки\" (спам-тексты с phone-хинтом, но не телефоны — допускаем как `Other`).\n",
    "    \n",
    "\n",
    "**Дальше:**  \n",
    "(1) включить CE-rerank как **опциональный флаг** только для low-margin кейсов,  \n",
    "(2) централизовать конфиг порогов (см. 06) и логирование решений,  \n",
    "(3) добавить легкую телеметрию (latency per step) для прод-профиля.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99bc932",
   "metadata": {
    "id": "d99bc932"
   },
   "source": [
    "# 06 · Пороги и калибровка\n",
    "\n",
    "**Цель.** Подобрать прод-пороги и температуру, формализовать OOD-параметры, зафиксировать **`inference_thresholds.json`**.\n",
    "\n",
    "**Что делаем**\n",
    "\n",
    "- Optuna/грид для `τ_other` и `temperature` на валидации.\n",
    "    \n",
    "- Подбор саб-порогов по покрытию/точности (macro-F1 + coverage).\n",
    "    \n",
    "- OOD-калибровка по распределению L2 CLS: `μ/σ`, `z_thr`, `alpha`, `dist_thr`.\n",
    "    \n",
    "\n",
    "**Результаты (на наших прогонах)**\n",
    "\n",
    "- **Main:** `tau_other = 0.2826`, `temperature = 0.917`.\n",
    "    \n",
    "- **Sub:** `autos_tau = 0.60`, `apart_tau = 0.30`.\n",
    "    \n",
    "- **OOD (CLS-L2 z-score):**  \n",
    "    `mu = 863.18`, `sigma = 675.82`, `alpha = 1.498`, `z_thr = 7.948`, `threshold ≈ 4141.65`.\n",
    "    \n",
    "\n",
    "**Выход**  \n",
    "`data/inference_thresholds.json` (консистентно читается в ноутбуке 05)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd061d7",
   "metadata": {
    "id": "efd061d7"
   },
   "source": [
    "## 1. Env setup (NumPy 2.x stack for Py3.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8iEOoQfNXbxb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iEOoQfNXbxb",
    "outputId": "f6dc8727-b0be-4110-925c-04afb0f54606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.11\n",
      "numpy: 1.26.4\n",
      "pandas: 2.3.2\n",
      "sklearn: 1.5.2\n",
      "torch: 2.8.0+cu126\n",
      "transformers: 4.56.1\n",
      "optuna: 3.6.2\n",
      "rapidfuzz: 3.6.2\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np, pandas as pd, torch, transformers, optuna, rapidfuzz, sklearn\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"optuna:\", optuna.__version__)\n",
    "print(\"rapidfuzz:\", rapidfuzz.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1146840",
   "metadata": {
    "id": "f1146840"
   },
   "source": [
    "## 2. Paths / Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aZGFWC1vYtEz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZGFWC1vYtEz",
    "outputId": "f3c40cb8-f00a-4323-8f5b-b2b32658401a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusermount: failed to unmount /content/drive: Invalid argument\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!fusermount -u /content/drive\n",
    "!rm -rf /content/drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcba0e72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcba0e72",
    "outputId": "85388015-4be6-49be-b820-3c4004bb5e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /content/drive/MyDrive/data_artifacts_AdAnalyser\n",
      "Exists: True True True\n",
      "Data: True True True\n",
      "Mapping source: config.id2label\n",
      "Num coarse classes: 50\n",
      "Sample pairs: [(0, 'Автоаксессуары'), (1, 'Аудиотехника'), (2, 'Велосипеды'), (3, 'Водный транспорт'), (4, 'Гаражи и парковки')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/data_artifacts_AdAnalyser\")\n",
    "\n",
    "MAIN_MODEL_DIR   = BASE_DIR / \"rubert_cls_model\"\n",
    "CE_MODEL_DIR     = BASE_DIR / \"cross_encoder_rubert\"\n",
    "HEADS_DIR        = BASE_DIR / \"heads\"\n",
    "CACHE_DIR        = BASE_DIR / \"caches\"\n",
    "THRESH_PATH      = BASE_DIR / \"inference_thresholds.json\"\n",
    "\n",
    "DATA_MAIN_SYN    = BASE_DIR / \"synthetic_ru_private_ads_50cats_10000_v2.csv\"\n",
    "DATA_AUTOS       = BASE_DIR / \"autos_subclf_30000.csv\"\n",
    "DATA_APART       = BASE_DIR / \"apartments_subclf_30000.csv\"\n",
    "\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "HEADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"Exists:\", MAIN_MODEL_DIR.exists(), CE_MODEL_DIR.exists(), THRESH_PATH.exists())\n",
    "print(\"Data:\", DATA_MAIN_SYN.exists(), DATA_AUTOS.exists(), DATA_APART.exists())\n",
    "\n",
    "#  Label mapping\n",
    "def _try_from_label_map(mp):\n",
    "    # {\"0\":\"Класс\"}\n",
    "    if isinstance(mp, dict) and all(k.isdigit() for k in mp.keys()) and all(isinstance(v, str) for v in mp.values()):\n",
    "        return {int(k): v for k, v in mp.items()}, \"dict[id:str]->label(str)\"\n",
    "\n",
    "    # {\"0\":[\"Класс\"]}\n",
    "    if isinstance(mp, dict) and all(k.isdigit() for k in mp.keys()) and \\\n",
    "       all(isinstance(v, list) and len(v) >= 1 and isinstance(v[0], str) for v in mp.values()):\n",
    "        return {int(k): v[0] for k, v in mp.items()}, \"dict[id:str]->list(label)\"\n",
    "\n",
    "    # {\"Класс\":\"0\"} или {\"Класс\":0}\n",
    "    if isinstance(mp, dict) and all(isinstance(k, str) for k in mp.keys()):\n",
    "        ok, tmp = True, {}\n",
    "        for lbl, val in mp.items():\n",
    "            if isinstance(val, int):\n",
    "                tmp[val] = lbl\n",
    "            elif isinstance(val, str) and val.isdigit():\n",
    "                tmp[int(val)] = lbl\n",
    "            elif isinstance(val, list) and len(val) and \\\n",
    "                 ((isinstance(val[0], int)) or (isinstance(val[0], str) and val[0].isdigit())):\n",
    "                tmp[int(val[0])] = lbl\n",
    "            else:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok and len(tmp):\n",
    "            return tmp, \"dict[label]->id(int/str/list)\"\n",
    "\n",
    "    # [\"Класс0\",\"Класс1\",...]\n",
    "    if isinstance(mp, list) and all(isinstance(v, str) for v in mp):\n",
    "        return {i: mp[i] for i in range(len(mp))}, \"list[label]\"\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def _try_from_config(cfg_path: Path):\n",
    "    if not cfg_path.exists():\n",
    "        return None, None\n",
    "    try:\n",
    "        cfg = json.load(open(cfg_path, \"r\", encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "    # id2label в config.json как {\"0\":\"Класс\"}\n",
    "    if isinstance(cfg.get(\"id2label\"), dict) and all(k.isdigit() for k in cfg[\"id2label\"].keys()):\n",
    "        return {int(k): v for k, v in cfg[\"id2label\"].items()}, \"config.id2label\"\n",
    "    # label2id в config.json как {\"Класс\":0}\n",
    "    if isinstance(cfg.get(\"label2id\"), dict):\n",
    "        mp = cfg[\"label2id\"]\n",
    "        tmp = {}\n",
    "        for lbl, val in mp.items():\n",
    "            if isinstance(val, int):\n",
    "                tmp[val] = lbl\n",
    "            elif isinstance(val, str) and val.isdigit():\n",
    "                tmp[int(val)] = lbl\n",
    "        if tmp:\n",
    "            return tmp, \"config.label2id\"\n",
    "    return None, None\n",
    "\n",
    "# читаем label_mapping.json\n",
    "label_map_path = MAIN_MODEL_DIR / \"label_mapping.json\"\n",
    "if not label_map_path.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {label_map_path}\")\n",
    "\n",
    "label_map = json.load(open(label_map_path, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "ID2LABEL, source = _try_from_label_map(label_map)\n",
    "if ID2LABEL is None:\n",
    "    # фолбэк на config.json\n",
    "    ID2LABEL, source = _try_from_config(MAIN_MODEL_DIR / \"config.json\")\n",
    "\n",
    "if ID2LABEL is None:\n",
    "    print(\"label_mapping.json SAMPLE:\", list(label_map.items())[:5])\n",
    "    raise ValueError(\"Unsupported label_mapping.json format and no usable mapping in config.json\")\n",
    "\n",
    "LABEL2ID = {v: k for k, v in ID2LABEL.items()}\n",
    "LABELS = [ID2LABEL[i] for i in sorted(ID2LABEL.keys())]\n",
    "\n",
    "print(f\"Mapping source: {source}\")\n",
    "print(\"Num coarse classes:\", len(LABELS))\n",
    "print(\"Sample pairs:\", list(ID2LABEL.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aefe9a",
   "metadata": {
    "id": "39aefe9a"
   },
   "source": [
    "## 3. Load thresholds (+defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ea0f1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3ea0f1c",
    "outputId": "1aec3069-8b57-4141-c0fa-262904abd264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau_other: 0.35 | tau_high: 0.75 | alpha: 1.0\n",
      "OOD -> z_thr: 7.947675119608771 | mu: 863.1790571325726 | sigma: 675.8236249816604 | thr_raw: 4141.648698247054\n",
      "Sub -> autos_tau: 0.8341092920652331 | apart_tau: 0.44362904422064614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, numpy as np\n",
    "\n",
    "T = json.load(open(THRESH_PATH, \"r\", encoding=\"utf-8\")) if THRESH_PATH.exists() else {}\n",
    "\n",
    "TAU_OTHER = float(T.get(\"main_tau_other\", 0.35))\n",
    "TAU_HIGH  = float(T.get(\"main_tau_high\", 0.75))\n",
    "ALPHA     = float(T.get(\"alpha\", 1.0))\n",
    "\n",
    "OOD = T.get(\"ood\", {})\n",
    "Z_THR = float(OOD.get(\"z_thr\", 8.0))\n",
    "MU    = float(OOD.get(\"mu\", 0.0))\n",
    "SIGMA = float(OOD.get(\"sigma\", 1.0))\n",
    "THR_RAW = OOD.get(\"threshold\", None)\n",
    "try: THR_RAW = float(THR_RAW) if THR_RAW is not None else None\n",
    "except: THR_RAW = None\n",
    "\n",
    "SUB = T.get(\"sub\", {})\n",
    "TAU_AUTOS  = float(SUB.get(\"autos_tau\", 0.83))\n",
    "TAU_APART  = float(SUB.get(\"apart_tau\", 0.45))\n",
    "\n",
    "print(\"tau_other:\", TAU_OTHER, \"| tau_high:\", TAU_HIGH, \"| alpha:\", ALPHA)\n",
    "print(\"OOD -> z_thr:\", Z_THR, \"| mu:\", MU, \"| sigma:\", SIGMA, \"| thr_raw:\", THR_RAW)\n",
    "print(\"Sub -> autos_tau:\", TAU_AUTOS, \"| apart_tau:\", TAU_APART)\n",
    "\n",
    "AUTOS_COARSE  = {\"Легковые автомобили\"}\n",
    "APART_COARSE  = {\"Квартиры — аренда\", \"Квартиры — продажа\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52ff74",
   "metadata": {
    "id": "1f52ff74"
   },
   "source": [
    "## 4. Load models (main, shared, CE?, heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22c9a17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d22c9a17",
    "outputId": "48b35234-0a0b-43ca-e14c-d075c86816da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "CE loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator _SigmoidCalibration from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads loaded: True True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import joblib\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else (\"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "main_tok  = AutoTokenizer.from_pretrained(str(MAIN_MODEL_DIR))\n",
    "main_clf  = AutoModelForSequenceClassification.from_pretrained(str(MAIN_MODEL_DIR)).to(DEVICE)\n",
    "main_clf.eval()\n",
    "\n",
    "shared_tok = main_tok\n",
    "shared_enc = AutoModel.from_pretrained(str(MAIN_MODEL_DIR)).to(DEVICE)\n",
    "shared_enc.eval()\n",
    "\n",
    "if CE_MODEL_DIR.exists():\n",
    "    try:\n",
    "        ce_tok = AutoTokenizer.from_pretrained(str(CE_MODEL_DIR))\n",
    "        ce_mdl = AutoModelForSequenceClassification.from_pretrained(str(CE_MODEL_DIR)).to(DEVICE)\n",
    "        ce_mdl.eval()\n",
    "        print(\"CE loaded.\")\n",
    "    except Exception as e:\n",
    "        ce_tok = None; ce_mdl = None\n",
    "        print(\"CE not loaded:\", e)\n",
    "else:\n",
    "    ce_tok = None; ce_mdl = None\n",
    "    print(\"CE folder not found.\")\n",
    "\n",
    "HEADS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "autos_head = joblib.load(HEADS_DIR / \"head_autos_brand.joblib\") if (HEADS_DIR / \"head_autos_brand.joblib\").exists() else None\n",
    "apart_head = joblib.load(HEADS_DIR / \"head_apart.joblib\")        if (HEADS_DIR / \"head_apart.joblib\").exists() else None\n",
    "print(\"Heads loaded:\", bool(autos_head), bool(apart_head))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10ae689",
   "metadata": {
    "id": "b10ae689"
   },
   "source": [
    "## 5. Helpers (infer, ood, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb5f6e81",
   "metadata": {
    "id": "fb5f6e81"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch, numpy as np, pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, log_loss\n",
    "\n",
    "@torch.inference_mode()\n",
    "def main_infer(texts, batch_size=64, temperature: float = 1.0):\n",
    "    res = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tok = main_tok(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(DEVICE)\n",
    "        out = main_clf(**tok)\n",
    "        logits = out.logits / max(1e-6, temperature)\n",
    "        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        res.append(probs)\n",
    "    probs = np.vstack(res) if res else np.zeros((0, len(LABELS)))\n",
    "    top_ids = probs.argmax(axis=1)\n",
    "    top_scores = probs.max(axis=1)\n",
    "    top_labels = [ID2LABEL[i] for i in top_ids]\n",
    "    return probs, top_labels, top_scores\n",
    "\n",
    "@torch.inference_mode()\n",
    "def cls_embeddings(texts, batch_size=128):\n",
    "    all_emb = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tok = shared_tok(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(DEVICE)\n",
    "        out = shared_enc(**tok, output_hidden_states=True, return_dict=True)\n",
    "        cls = out.last_hidden_state[:,0,:].detach().cpu().numpy()\n",
    "        all_emb.append(cls)\n",
    "    return np.vstack(all_emb) if all_emb else np.zeros((0, shared_enc.config.hidden_size))\n",
    "\n",
    "def apply_thresh(labels, scores, tau=0.35, per_label_tau: dict = None):\n",
    "    out = []\n",
    "    for l, s in zip(labels, scores):\n",
    "        thr = per_label_tau.get(l, tau) if per_label_tau else tau\n",
    "        out.append(l if s >= thr else \"Other\")\n",
    "    return out\n",
    "\n",
    "def eval_report(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    print(\"Acc:\", round(accuracy_score(y_true, y_pred), 4))\n",
    "    print(\"F1(macro):\", round(f1_score(y_true, y_pred, average=\"macro\"), 4))\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "def ood_stub(probs):\n",
    "    maxp = probs.max(axis=1)\n",
    "    z = (1.0 - maxp)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e615808",
   "metadata": {
    "id": "8e615808"
   },
   "source": [
    "## 6. Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae62467",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "cae62467",
    "outputId": "fe64ce4e-d903-44ce-c3dd-c9fdc9983cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main (10000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"display(df_main\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\u041f\\u0440\\u043e\\u0434\\u0430\\u044e \\u0430\\u0432\\u0442\\u043e\\u0430\\u043a\\u0441\\u0435\\u0441\\u0441\\u0443\\u0430\\u0440\\u044b \\u2014 \\u0421\\u0430\\u043d\\u043a\\u0442-\\u041f\\u0435\\u0442\\u0435\\u0440\\u0431\\u0443\\u0440\\u0433 \\u041f\\u043e\\u043a\\u0430\\u0436\\u0443 \\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f. \\u0411\\u0435\\u0437 \\u0434\\u0442\\u043f. \\u0414\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\\u044b \\u0432 \\u043d\\u0430\\u043b\\u0438\\u0447\\u0438\\u0438. \\u0412\\u043e\\u0437\\u043c\\u043e\\u0436\\u0435\\u043d \\u0442\\u043e\\u0440\\u0433. \\u0421\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0435 \\u043e\\u0442\\u043b\\u0438\\u0447\\u043d\\u043e\\u0435. \\u0413\\u043e\\u0440\\u043e\\u0434: \\u0422\\u044e\\u043c\\u0435\\u043d\\u044c.\",\n          \"\\u041f\\u0440\\u043e\\u0434\\u0430\\u044e \\u0430\\u0432\\u0442\\u043e\\u0430\\u043a\\u0441\\u0435\\u0441\\u0441\\u0443\\u0430\\u0440\\u044b \\u2014 \\u041a\\u0430\\u0437\\u0430\\u043d\\u044c \\u0413\\u043e\\u0440\\u043e\\u0434: \\u0412\\u043e\\u0440\\u043e\\u043d\\u0435\\u0436. \\u0414\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043d\\u0430\\u044f. \\u041e\\u0431\\u0441\\u043b\\u0443\\u0436\\u0438\\u0432\\u0430\\u043d\\u0438\\u0435 \\u0443 \\u0434\\u0438\\u043b\\u0435\\u0440\\u0430. \\u0411\\u0435\\u0437 \\u043f\\u043e\\u0441\\u0440\\u0435\\u0434\\u043d\\u0438\\u043a\\u043e\\u0432. \\u0417\\u0432\\u043e\\u043d\\u0438\\u0442\\u0435 / \\u043f\\u0438\\u0448\\u0438\\u0442\\u0435. \\u0414\\u043e\\u0441\\u0442\\u0430\\u0432\\u043a\\u0430 \\u043f\\u043e \\u0433\\u043e\\u0440\\u043e\\u0434\\u0443. \\u0411\\u0435\\u0440\\u0435\\u0436\\u043d\\u0430\\u044f \\u044d\\u043a\\u0441\\u043f\\u043b\\u0443\\u0430\\u0442\\u0430\\u0446\\u0438\\u044f.\",\n          \"\\u0412 \\u043f\\u0440\\u043e\\u0434\\u0430\\u0436\\u0435 \\u0430\\u0432\\u0442\\u043e\\u0430\\u043a\\u0441\\u0435\\u0441\\u0441\\u0443\\u0430\\u0440\\u044b \\u2014 \\u041d\\u0438\\u0436\\u043d\\u0438\\u0439 \\u041d\\u043e\\u0432\\u0433\\u043e\\u0440\\u043e\\u0434 \\u0413\\u0430\\u0440\\u0430\\u0436\\u043d\\u043e\\u0435 \\u0445\\u0440\\u0430\\u043d\\u0435\\u043d\\u0438\\u0435. \\u0413\\u043e\\u0440\\u043e\\u0434: \\u041d\\u043e\\u0432\\u043e\\u0441\\u0438\\u0431\\u0438\\u0440\\u0441\\u043a. \\u041f\\u043e\\u043a\\u0430\\u0436\\u0443 \\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f. \\u0420\\u0430\\u0437\\u0443\\u043c\\u043d\\u044b\\u0439 \\u0442\\u043e\\u0440\\u0433.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0410\\u0432\\u0442\\u043e\\u0430\\u043a\\u0441\\u0435\\u0441\\u0441\\u0443\\u0430\\u0440\\u044b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2c59fe4d-d7fb-44fd-a6a0-8aaddb0b8b96\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Продаю автоаксессуары — Санкт-Петербург Покажу...</td>\n",
       "      <td>Автоаксессуары</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Продаю автоаксессуары — Казань Город: Воронеж....</td>\n",
       "      <td>Автоаксессуары</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В продаже автоаксессуары — Нижний Новгород Гар...</td>\n",
       "      <td>Автоаксессуары</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c59fe4d-d7fb-44fd-a6a0-8aaddb0b8b96')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2c59fe4d-d7fb-44fd-a6a0-8aaddb0b8b96 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2c59fe4d-d7fb-44fd-a6a0-8aaddb0b8b96');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-5b1d6583-bc8e-4adb-9729-1aeb85eb4fbc\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b1d6583-bc8e-4adb-9729-1aeb85eb4fbc')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-5b1d6583-bc8e-4adb-9729-1aeb85eb4fbc button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  Продаю автоаксессуары — Санкт-Петербург Покажу...  Автоаксессуары\n",
       "1  Продаю автоаксессуары — Казань Город: Воронеж....  Автоаксессуары\n",
       "2  В продаже автоаксессуары — Нижний Новгород Гар...  Автоаксессуары"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io, pandas as pd\n",
    "from ftfy import fix_text\n",
    "\n",
    "def _score_text(s: str) -> int:\n",
    "    cyr = sum('А' <= ch <= 'я' or ch in 'ее' for ch in s)\n",
    "    junk = sum(s.count(t) for t in ['â', 'Ä', '™', '‚', 'œ'])\n",
    "    return cyr - 4 * junk\n",
    "\n",
    "def smart_read_ads_csv(path):\n",
    "    raw = open(path, 'rb').read()\n",
    "    candidates = ['utf-8', 'utf-8-sig', 'cp1251', 'windows-1251', 'latin1']\n",
    "    best = None; best_enc = None; best_score = -10**9\n",
    "\n",
    "    for enc in candidates:\n",
    "        try:\n",
    "            df_try = pd.read_csv(io.BytesIO(raw), encoding=enc)\n",
    "            # формируем временный текст для оценки читабельности\n",
    "            tt = (df_try.get('title', pd.Series(dtype=str)).astype(str).head(200).str.cat(sep=' ')\n",
    "                  + ' ' +\n",
    "                  df_try.get('description', pd.Series(dtype=str)).astype(str).head(200).str.cat(sep=' '))\n",
    "            score = _score_text(tt)\n",
    "            if score > best_score:\n",
    "                best_score, best, best_enc = score, df_try, enc\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    df = best.copy()\n",
    "    # если кодировка оказалась latin1 — почти наверняка mojibake далее чиним текстовые поля\n",
    "    if best_enc == 'latin1':\n",
    "        for col in ['title', 'description', 'category']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).apply(fix_text)\n",
    "\n",
    "    # собираем нужные колонки text/label\n",
    "    if 'title' in df.columns or 'description' in df.columns:\n",
    "        title = df.get('title', '')\n",
    "        descr = df.get('description', '')\n",
    "        df['text'] = title.fillna('') + ' ' + descr.fillna('')\n",
    "    else:\n",
    "        raise KeyError(f\"Нет колонок title/description, нашли: {df.columns.tolist()}\")\n",
    "\n",
    "    if 'category' in df.columns:\n",
    "        df = df.rename(columns={'category':'label'})\n",
    "    elif 'label' not in df.columns:\n",
    "        raise KeyError(f\"Нет колонки category/label, нашли: {df.columns.tolist()}\")\n",
    "\n",
    "    return df[['text','label']]\n",
    "\n",
    "# Используем:\n",
    "df_main = smart_read_ads_csv(str(DATA_MAIN_SYN))\n",
    "print('main', df_main.shape)\n",
    "display(df_main.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3528940",
   "metadata": {
    "id": "c3528940"
   },
   "source": [
    "## 7. Cache CLS embeddings for sub-heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76ef899b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76ef899b",
    "outputId": "89519b84-59b7-4e80-c4b4-f353c63a0236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache: /content/drive/MyDrive/data_artifacts_AdAnalyser/caches/val_autos_cls.npy True\n",
      "cache: /content/drive/MyDrive/data_artifacts_AdAnalyser/caches/val_apart_cls.npy True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AUTOS_CACHE = CACHE_DIR / \"val_autos_cls.npy\"\n",
    "APART_CACHE = CACHE_DIR / \"val_apart_cls.npy\"\n",
    "\n",
    "if df_autos is not None:\n",
    "    if not AUTOS_CACHE.exists():\n",
    "        emb_a = cls_embeddings(df_autos[\"text\"].tolist())\n",
    "        np.save(AUTOS_CACHE, emb_a)\n",
    "    else:\n",
    "        emb_a = np.load(AUTOS_CACHE)\n",
    "\n",
    "if df_apart is not None:\n",
    "    if not APART_CACHE.exists():\n",
    "        emb_p = cls_embeddings(df_apart[\"text\"].tolist())\n",
    "        np.save(APART_CACHE, emb_p)\n",
    "    else:\n",
    "        emb_p = np.load(APART_CACHE)\n",
    "\n",
    "for p in [AUTOS_CACHE, APART_CACHE]:\n",
    "    print(\"cache:\", p, p.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717d8be",
   "metadata": {
    "id": "b717d8be"
   },
   "source": [
    "## 8. Baseline & Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34f5b286",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34f5b286",
    "outputId": "e85d33ec-4a67-40ef-e3ec-9e39368ad4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline -> Score: 0.9859 | Acc: 0.9927 | F1: 0.9757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main_eval_block(df, tau=0.35, temperature=1.0):\n",
    "    probs, top_labels, top_scores = main_infer(df[\"text\"].tolist(), temperature=temperature)\n",
    "    pred_after_tau = apply_thresh(top_labels, top_scores, tau=tau)\n",
    "    return {\n",
    "        \"labels\": top_labels,\n",
    "        \"scores\": top_scores,\n",
    "        \"pred_tau\": pred_after_tau,\n",
    "        \"probs\": probs\n",
    "    }\n",
    "\n",
    "def score_pipeline(df, tau=0.35, temperature=1.0, weight_acc=0.6, weight_f1=0.4):\n",
    "    y_true = df[\"label\"].tolist()\n",
    "    out = main_eval_block(df, tau=tau, temperature=temperature)\n",
    "    y_pred = out[\"pred_tau\"]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return weight_acc*acc + weight_f1*f1, acc, f1\n",
    "\n",
    "if df_main is not None:\n",
    "    s, acc, f1m = score_pipeline(df_main, tau=TAU_OTHER, temperature=float(T.get(\"temperature\", 1.0)))\n",
    "    print(\"Baseline -> Score:\", round(s,4), \"| Acc:\", round(acc,4), \"| F1:\", round(f1m,4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5334915",
   "metadata": {
    "id": "a5334915"
   },
   "source": [
    "## 9. Optuna: tune tau_other & temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d94c28f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d94c28f8",
    "outputId": "0b50c066-5790-4d4a-f160-b0deb7fb745e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 03:58:03,220] A new study created in memory with name: no-name-5994f7ce-70f0-4fbb-b485-eb5327d52dc9\n",
      "[I 2025-09-08 03:58:27,033] Trial 0 finished with value: 0.9803017027945589 and parameters: {'tau_other': 0.6963247701593592, 'temperature': 0.799933612457451}. Best is trial 0 with value: 0.9803017027945589.\n",
      "[I 2025-09-08 03:58:51,552] Trial 1 finished with value: 0.9831688669345943 and parameters: {'tau_other': 0.451626612870048, 'temperature': 1.0792416950482666}. Best is trial 1 with value: 0.9831688669345943.\n",
      "[I 2025-09-08 03:59:16,117] Trial 2 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.2825582677025756, 'temperature': 0.91699954894511}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 03:59:39,634] Trial 3 finished with value: 0.9732339616513854 and parameters: {'tau_other': 0.6809534140172065, 'temperature': 0.9332571589384284}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:00:03,009] Trial 4 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.17813919117414456, 'temperature': 1.2081978957972792}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:00:26,821] Trial 5 finished with value: 0.9842996549644929 and parameters: {'tau_other': 0.6003634371237723, 'temperature': 0.7947700033248487}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:00:50,834] Trial 6 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.4506616725979794, 'temperature': 0.8133972581267593}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:01:13,870] Trial 7 finished with value: 0.9860087818249371 and parameters: {'tau_other': 0.282000288269164, 'temperature': 0.740753024308123}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:01:36,883] Trial 8 finished with value: 0.0 and parameters: {'tau_other': 0.6716635698552504, 'temperature': 1.3401830188945503}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:01:59,910] Trial 9 finished with value: 0.753013545367646 and parameters: {'tau_other': 0.6610885754127689, 'temperature': 1.139193563357433}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:02:22,978] Trial 10 finished with value: 0.9856486397544275 and parameters: {'tau_other': 0.1006958538063207, 'temperature': 0.9943257545305224}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:02:45,926] Trial 11 finished with value: 0.9858883896582703 and parameters: {'tau_other': 0.21171853210799074, 'temperature': 1.2895159308753354}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:03:08,939] Trial 12 finished with value: 0.9812405679177774 and parameters: {'tau_other': 0.2828039254173311, 'temperature': 1.477197407344645}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:03:31,991] Trial 13 finished with value: 0.9859314146075232 and parameters: {'tau_other': 0.10362369819673735, 'temperature': 1.205358984032206}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:03:55,068] Trial 14 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.2253400012108954, 'temperature': 0.9840193684870175}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:04:18,153] Trial 15 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.34247183963972194, 'temperature': 0.9234573935491523}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:04:41,262] Trial 16 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.18453904941858884, 'temperature': 1.085428904923242}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:05:04,386] Trial 17 finished with value: 0.9818070322103825 and parameters: {'tau_other': 0.36790449273203374, 'temperature': 1.2591353453791765}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:05:27,492] Trial 18 finished with value: 0.0 and parameters: {'tau_other': 0.5330494737261817, 'temperature': 1.4225187666456482}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:05:50,625] Trial 19 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.17469114470054234, 'temperature': 1.1677928111101217}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:06:13,687] Trial 20 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.28715661150899563, 'temperature': 1.0361528253724774}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:06:36,772] Trial 21 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.4266071866114039, 'temperature': 0.8323431125063167}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:06:59,841] Trial 22 finished with value: 0.9849713653528629 and parameters: {'tau_other': 0.5191925514438229, 'temperature': 0.8844324436483816}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:07:22,955] Trial 23 finished with value: 0.9859427033223354 and parameters: {'tau_other': 0.49220849370112185, 'temperature': 0.735238475615239}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:07:46,007] Trial 24 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.32959026345931536, 'temperature': 0.864094132576754}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:08:09,069] Trial 25 finished with value: 0.986028243462522 and parameters: {'tau_other': 0.39566910351821766, 'temperature': 0.7030663256557979}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:08:32,198] Trial 26 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.2538919729937515, 'temperature': 0.9398119160936504}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:08:55,314] Trial 27 finished with value: 0.9859892228791642 and parameters: {'tau_other': 0.14864917274360154, 'temperature': 1.013488831359602}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:09:18,450] Trial 28 finished with value: 0.9847610050226739 and parameters: {'tau_other': 0.31618750400349355, 'temperature': 1.2168819537591566}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:09:41,507] Trial 29 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.46830617000156677, 'temperature': 0.7675548830280672}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:10:04,604] Trial 30 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.3896400060593719, 'temperature': 0.8296355455818073}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:10:27,723] Trial 31 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.2271349696323641, 'temperature': 0.9731224826649499}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:10:50,818] Trial 32 finished with value: 0.9860087818249371 and parameters: {'tau_other': 0.1462663711820066, 'temperature': 1.055464205843861}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:11:13,906] Trial 33 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.24130252450117884, 'temperature': 1.133275753753955}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:11:37,011] Trial 34 finished with value: 0.9858883896582703 and parameters: {'tau_other': 0.4396662698041034, 'temperature': 0.8807769205831055}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:12:00,175] Trial 35 finished with value: 0.9860087818249371 and parameters: {'tau_other': 0.20008224094775567, 'temperature': 0.9553888540418061}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:12:23,304] Trial 36 finished with value: 0.9846052664419243 and parameters: {'tau_other': 0.5785578628371149, 'temperature': 0.8057782453562125}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:12:46,460] Trial 37 finished with value: 0.986028243462522 and parameters: {'tau_other': 0.25907377268626086, 'temperature': 0.8940661328621106}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:13:09,558] Trial 38 finished with value: 0.9860478024082948 and parameters: {'tau_other': 0.15565369572254406, 'temperature': 1.3828029323172053}. Best is trial 2 with value: 0.9860478024082948.\n",
      "[I 2025-09-08 04:13:32,684] Trial 39 finished with value: 0.9858883896582703 and parameters: {'tau_other': 0.3512941412624722, 'temperature': 1.0168346490414482}. Best is trial 2 with value: 0.9860478024082948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: {'tau_other': 0.2825582677025756, 'temperature': 0.91699954894511}\n",
      "Acc: 0.9929 F1: 0.9757695060207371\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    tau = trial.suggest_float(\"tau_other\", 0.10, 0.70)\n",
    "    temp = trial.suggest_float(\"temperature\", 0.7, 1.5)\n",
    "    s, acc, f1m = score_pipeline(df_main, tau=tau, temperature=temp)\n",
    "    trial.set_user_attr(\"acc\", acc)\n",
    "    trial.set_user_attr(\"f1\", f1m)\n",
    "    return s\n",
    "\n",
    "if df_main is not None:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=40, show_progress_bar=False)\n",
    "    best = study.best_params\n",
    "    print(\"Best:\", best)\n",
    "    print(\"Acc:\", study.best_trial.user_attrs.get(\"acc\"), \"F1:\", study.best_trial.user_attrs.get(\"f1\"))\n",
    "else:\n",
    "    best = {\"tau_other\": TAU_OTHER, \"temperature\": float(T.get(\"temperature\", 1.0))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576ccaa",
   "metadata": {
    "id": "f576ccaa"
   },
   "source": [
    "## 10. Tune sub thresholds (autos/apart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d9d729c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d9d729c",
    "outputId": "39532b5f-b125-4ef3-e7c1-8e728484cd87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos head: CalibratedClassifierCV | classes: 20 | emb: (5000, 768)\n",
      "Apart head: CalibratedClassifierCV | classes: 10 | emb: (5000, 768)\n",
      "\n",
      "Best main: {'tau_other': 0.283, 'temperature': 0.917}\n",
      "Best sub: {'autos_tau': 0.6, 'apart_tau': 0.3}\n",
      "Top autos grid: [(0.6, 0.29946), (0.61625, 0.29928), (0.6325, 0.29916)]\n",
      "Top apart grid: [(0.3, 0.29946), (0.325, 0.2985), (0.35, 0.29712)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np, json, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Пути\n",
    "BASE_DIR  = Path(globals().get(\"BASE_DIR\", \"/content/drive/MyDrive/data_artifacts_AdAnalyser\"))\n",
    "HEADS_DIR = Path(globals().get(\"HEADS_DIR\", BASE_DIR / \"heads\"))\n",
    "CACHE_DIR = Path(globals().get(\"CACHE_DIR\", BASE_DIR / \"caches\"))\n",
    "THRESH_P  = Path(globals().get(\"THRESH_PATH\", BASE_DIR / \"inference_thresholds.json\"))\n",
    "\n",
    "HEAD_AUTOS = HEADS_DIR / \"head_autos_brand.joblib\"\n",
    "HEAD_APART = HEADS_DIR / \"head_apart.joblib\"\n",
    "EMB_AUTOS  = CACHE_DIR / \"autos_cls_emb.npy\"\n",
    "EMB_APART  = CACHE_DIR / \"apart_cls_emb.npy\"\n",
    "\n",
    "# helpers\n",
    "def _unwrap_estimator(head_obj):\n",
    "    \"\"\"Вернет sklearn-estimator с predict_proba из dict/tuple/Pipeline/самой модели.\"\"\"\n",
    "    if head_obj is None:\n",
    "        return None\n",
    "    # уже модель\n",
    "    if hasattr(head_obj, \"predict_proba\"):\n",
    "        return head_obj\n",
    "    # dict: ищем по типичным ключам\n",
    "    if isinstance(head_obj, dict):\n",
    "        for k in (\"model\",\"clf\",\"estimator\",\"pipe\",\"sk_model\",\"pipeline\"):\n",
    "            v = head_obj.get(k)\n",
    "            if hasattr(v, \"predict_proba\"):\n",
    "                return v\n",
    "        # иначе ищем в значениях\n",
    "        for v in head_obj.values():\n",
    "            if hasattr(v, \"predict_proba\"):\n",
    "                return v\n",
    "    # tuple/list: ищем внутри\n",
    "    if isinstance(head_obj, (list, tuple)):\n",
    "        for v in head_obj:\n",
    "            if hasattr(v, \"predict_proba\"):\n",
    "                return v\n",
    "    return None\n",
    "\n",
    "def _extract_classes(head_obj, est):\n",
    "    \"\"\"Вернет np.array имен классов.\"\"\"\n",
    "    if est is not None and hasattr(est, \"classes_\"):\n",
    "        return np.array(list(est.classes_), dtype=str)\n",
    "    if isinstance(head_obj, dict):\n",
    "        for k in (\"classes_\", \"classes\", \"class_names\", \"labels\"):\n",
    "            if k in head_obj:\n",
    "                return np.array(list(head_obj[k]), dtype=str)\n",
    "    return None\n",
    "\n",
    "def _ensure_head_and_classes(var_obj, fallback_path: Path):\n",
    "    \"\"\"Берет объект из переменной (если есть), иначе грузит joblib; распаковывает модель и классы.\"\"\"\n",
    "    obj = var_obj\n",
    "    if obj is None and fallback_path.exists():\n",
    "        obj = joblib.load(fallback_path)\n",
    "    est = _unwrap_estimator(obj)\n",
    "    classes = _extract_classes(obj, est)\n",
    "    return est, classes\n",
    "\n",
    "def _ensure_emb(var_name: str, path: Path):\n",
    "    \"\"\"Возвращает эмбеддинги из переменной, либо грузит .npy из кеша.\"\"\"\n",
    "    arr = globals().get(var_name, None)\n",
    "    if arr is None and path.exists():\n",
    "        arr = np.load(path)\n",
    "    if arr is not None and arr.ndim != 2:\n",
    "        raise ValueError(f\"{var_name} должен быть матрицей [N, D], shape={arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "# heads & embeddings\n",
    "autos_est, autos_classes = _ensure_head_and_classes(globals().get(\"autos_head\", None), HEAD_AUTOS)\n",
    "apart_est, apart_classes = _ensure_head_and_classes(globals().get(\"apart_head\", None), HEAD_APART)\n",
    "\n",
    "emb_a = _ensure_emb(\"emb_a\", EMB_AUTOS)  # CLS-эмбеддинги для авто\n",
    "emb_p = _ensure_emb(\"emb_p\", EMB_APART)   # CLS-эмбеддинги для квартир\n",
    "\n",
    "print(\"Autos head:\", None if autos_est is None else type(autos_est).__name__,\n",
    "      \"| classes:\", None if autos_classes is None else len(autos_classes),\n",
    "      \"| emb:\", None if emb_a is None else emb_a.shape)\n",
    "print(\"Apart head:\", None if apart_est is None else type(apart_est).__name__,\n",
    "      \"| classes:\", None if apart_classes is None else len(apart_classes),\n",
    "      \"| emb:\", None if emb_p is None else emb_p.shape)\n",
    "\n",
    "# проверяем датасеты\n",
    "if \"df_autos\" not in globals() or df_autos is None:\n",
    "    print(\"[warn] df_autos отсутствует — метрика для авто будет 0.\")\n",
    "if \"df_apart\" not in globals() or df_apart is None:\n",
    "    print(\"[warn] df_apart отсутствует — метрика для квартир будет 0.\")\n",
    "\n",
    "# metrics\n",
    "def _score_macro_f_cov(y_true, y_pred):\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    cov = (np.asarray(y_pred) != \"Other\").mean()\n",
    "    return 0.7 * float(f) + 0.3 * float(cov)\n",
    "\n",
    "def sub_score_autos(thr: float) -> float:\n",
    "    if autos_est is None or autos_classes is None or emb_a is None or \"df_autos\" not in globals() or df_autos is None:\n",
    "        return 0.0\n",
    "    P = autos_est.predict_proba(emb_a)\n",
    "    idx = P.argmax(axis=1)\n",
    "    prb = P.max(axis=1)\n",
    "    y_pred = np.where(prb >= thr, autos_classes[idx], \"Other\")\n",
    "    y_true = df_autos[\"label\"].astype(str).values\n",
    "    return _score_macro_f_cov(y_true, y_pred)\n",
    "\n",
    "def sub_score_apart(thr: float) -> float:\n",
    "    if apart_est is None or apart_classes is None or emb_p is None or \"df_apart\" not in globals() or df_apart is None:\n",
    "        return 0.0\n",
    "    P = apart_est.predict_proba(emb_p)\n",
    "    idx = P.argmax(axis=1)\n",
    "    prb = P.max(axis=1)\n",
    "    y_pred = np.where(prb >= thr, apart_classes[idx], \"Other\")\n",
    "    y_true = df_apart[\"label\"].astype(str).values\n",
    "    return _score_macro_f_cov(y_true, y_pred)\n",
    "\n",
    "def tune_scalar(func, low=0.3, high=0.99, steps=30):\n",
    "    grid = np.linspace(low, high, steps).astype(float)\n",
    "    vals = [(float(x), float(func(float(x)))) for x in grid]\n",
    "    vals.sort(key=lambda t: t[1], reverse=True)\n",
    "    return vals[0][0], vals[:5]\n",
    "\n",
    "# run tuning — основные из Optuna\n",
    "best_tau  = float(globals().get(\"best\", {}).get(\"tau_other\", globals().get(\"TAU_OTHER\", 0.35)))\n",
    "best_temp = float(globals().get(\"best\", {}).get(\"temperature\", float(globals().get(\"T\", {}).get(\"temperature\", 1.0))))\n",
    "\n",
    "best_autos, topA = tune_scalar(sub_score_autos, low=0.60, high=0.99, steps=25)\n",
    "best_apart, topP = tune_scalar(sub_score_apart, low=0.30, high=0.90, steps=25)\n",
    "\n",
    "print(\"\\nBest main:\", dict(tau_other=round(best_tau,3), temperature=round(best_temp,3)))\n",
    "print(\"Best sub:\",  dict(autos_tau=round(best_autos,3), apart_tau=round(best_apart,3)))\n",
    "print(\"Top autos grid:\", topA[:3])\n",
    "print(\"Top apart grid:\", topP[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2e988",
   "metadata": {
    "id": "0db2e988"
   },
   "source": [
    "## 11. Save updated thresholds -> inference_thresholds.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97ec30b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97ec30b8",
    "outputId": "0614f418-1144-4055-eeff-ec0897c57111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /content/drive/MyDrive/data_artifacts_AdAnalyser/inference_thresholds.json\n",
      "{\n",
      "  \"ood\": {\n",
      "    \"threshold\": 4141.648698247054,\n",
      "    \"alpha\": 1.49839657065949,\n",
      "    \"z_thr\": 7.947675119608771,\n",
      "    \"mu\": 863.1790571325726,\n",
      "    \"sigma\": 675.8236249816604\n",
      "  },\n",
      "  \"sub\": {\n",
      "    \"autos_tau\": 0.6,\n",
      "    \"apart_tau\": 0.3\n",
      "  },\n",
      "  \"main_tau_other\": 0.2825582677025756,\n",
      "  \"artifacts_root\": \"/content/drive/MyDrive/data_artifacts_AdAnalyser\",\n",
      "  \"main_tau_high\": 0.75,\n",
      "  \"alpha\": 1.0,\n",
      "  \"temperature\": 0.91699954894511\n",
      "} ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newT = dict(T)\n",
    "newT[\"main_tau_other\"] = float(best_tau)\n",
    "newT[\"main_tau_high\"]  = float(TAU_HIGH)\n",
    "newT[\"alpha\"]          = float(ALPHA)\n",
    "newT[\"temperature\"]    = float(best_temp)\n",
    "newT[\"sub\"] = dict(newT.get(\"sub\", {}), autos_tau=float(best_autos), apart_tau=float(best_apart))\n",
    "\n",
    "with open(THRESH_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(newT, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved:\", THRESH_PATH)\n",
    "print(json.dumps(newT, ensure_ascii=False, indent=2)[:600], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad4547",
   "metadata": {
    "id": "c5ad4547"
   },
   "source": [
    "## 12. Sanity mini-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2644bbd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2644bbd1",
    "outputId": "af7dbdca-2f7f-430f-e71e-96cf78b9e54f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\u041f\\u0440\\u043e\\u0434\\u0430\\u044e \\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u044c Toyota Camry 2019, \\u0430\\u0432\\u0442\\u043e\\u043c\\u0430\\u0442, \\u043e\\u0434\\u0438\\u043d \\u0445\\u043e\\u0437\\u044f\\u0438\\u043d\",\n          \"\\u041f\\u0440\\u043e\\u0434\\u0430\\u043c Kia Rio, 1.6, \\u043f\\u0440\\u043e\\u0431\\u0435\\u0433 52 \\u0442\\u044b\\u0441, \\u0431\\u0435\\u0437 \\u0432\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u0439\",\n          \"iPhone 12, 128GB, \\u0431/\\u0443, \\u0431\\u0430\\u0442\\u0430\\u0440\\u0435\\u044f 90%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coarse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0417\\u0430\\u043f\\u0447\\u0430\\u0441\\u0442\\u0438 \\u0434\\u043b\\u044f \\u0430\\u0432\\u0442\\u043e\",\n          \"\\u0421\\u043c\\u0430\\u0440\\u0442\\u0444\\u043e\\u043d\\u044b\",\n          \"\\u041a\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u044b \\u2014 \\u043f\\u0440\\u043e\\u0434\\u0430\\u0436\\u0430\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4569999873638153,\n          0.2029999941587448,\n          0.5740000009536743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after_tau\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Other\",\n          \"\\u0421\\u043c\\u0430\\u0440\\u0442\\u0444\\u043e\\u043d\\u044b\",\n          \"\\u041a\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u044b \\u2014 \\u043f\\u0440\\u043e\\u0434\\u0430\\u0436\\u0430\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e5489d4a-9432-47cb-9583-db4e1493c187\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>coarse</th>\n",
       "      <th>score</th>\n",
       "      <th>after_tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Продаю автомобиль Toyota Camry 2019, автомат, ...</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "      <td>0.457</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Продам Kia Rio, 1.6, пробег 52 тыс, без вложений</td>\n",
       "      <td>Запчасти для авто</td>\n",
       "      <td>0.203</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW 3 серии, 2016 год, М-пакет, обмен возможен</td>\n",
       "      <td>Легковые автомобили</td>\n",
       "      <td>0.162</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Квартира в Москве, 2 комнаты, продажа от собст...</td>\n",
       "      <td>Квартиры — продажа</td>\n",
       "      <td>0.356</td>\n",
       "      <td>Квартиры — продажа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сдам 2-комнатную квартиру в центре</td>\n",
       "      <td>Квартиры — аренда</td>\n",
       "      <td>0.518</td>\n",
       "      <td>Квартиры — аренда</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iPhone 12, 128GB, б/у, батарея 90%</td>\n",
       "      <td>Смартфоны</td>\n",
       "      <td>0.574</td>\n",
       "      <td>Смартфоны</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>кликайте по ссылке и выигрывайте айфон 15 бесп...</td>\n",
       "      <td>Смартфоны</td>\n",
       "      <td>0.190</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5489d4a-9432-47cb-9583-db4e1493c187')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e5489d4a-9432-47cb-9583-db4e1493c187 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e5489d4a-9432-47cb-9583-db4e1493c187');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-27176688-4df7-4c48-b8bf-796fa4598341\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27176688-4df7-4c48-b8bf-796fa4598341')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-27176688-4df7-4c48-b8bf-796fa4598341 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text               coarse  \\\n",
       "0  Продаю автомобиль Toyota Camry 2019, автомат, ...  Легковые автомобили   \n",
       "1   Продам Kia Rio, 1.6, пробег 52 тыс, без вложений    Запчасти для авто   \n",
       "2     BMW 3 серии, 2016 год, М-пакет, обмен возможен  Легковые автомобили   \n",
       "3  Квартира в Москве, 2 комнаты, продажа от собст...   Квартиры — продажа   \n",
       "4                 Сдам 2-комнатную квартиру в центре    Квартиры — аренда   \n",
       "5                 iPhone 12, 128GB, б/у, батарея 90%            Смартфоны   \n",
       "6  кликайте по ссылке и выигрывайте айфон 15 бесп...            Смартфоны   \n",
       "\n",
       "   score            after_tau  \n",
       "0  0.457  Легковые автомобили  \n",
       "1  0.203                Other  \n",
       "2  0.162                Other  \n",
       "3  0.356   Квартиры — продажа  \n",
       "4  0.518    Квартиры — аренда  \n",
       "5  0.574            Смартфоны  \n",
       "6  0.190                Other  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "samples = [\n",
    "    \"Продаю автомобиль Toyota Camry 2019, автомат, один хозяин\",\n",
    "    \"Продам Kia Rio, 1.6, пробег 52 тыс, без вложений\",\n",
    "    \"BMW 3 серии, 2016 год, М-пакет, обмен возможен\",\n",
    "    \"Квартира в Москве, 2 комнаты, продажа от собственника\",\n",
    "    \"Сдам 2-комнатную квартиру в центре\",\n",
    "    \"iPhone 12, 128GB, б/у, батарея 90%\",\n",
    "    \"кликайте по ссылке и выигрывайте айфон 15 бесплатно\",\n",
    "]\n",
    "\n",
    "probs, labs, scrs = main_infer(samples, temperature=newT.get(\"temperature\", 1.0))\n",
    "pred = apply_thresh(labs, scrs, tau=newT[\"main_tau_other\"])\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"text\": samples, \"coarse\": labs, \"score\": np.round(scrs,3), \"after_tau\": pred})\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b1715-23c4-4163-bdd3-20bee4810cdd",
   "metadata": {},
   "source": [
    "## Итоги (06 · Thresholds)\n",
    "\n",
    "- Калибровка завершена, пороги зафиксированы в общем конфиге.\n",
    "    \n",
    "- Баланс \"качество <=> покрытие <=> стабильность\" документированость.\n",
    "    \n",
    "- Все компоненты пайплайна (05) читают **один** конфиг порогов.\n",
    "    \n",
    "\n",
    "**Дальше:**  \n",
    "(1) рантайм-метрики попаданий/отсечений для контроля дрейфа,  \n",
    "(2) периодический пересчет `τ` и OOD-параметров оффлайн,  \n",
    "(3) A/B-exploration порогов на свежем трафике (если появится).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "report-analysis",
   "language": "python",
   "name": "report-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

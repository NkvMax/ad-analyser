
# Ad-Analyser · Продвинутая классификация объявлений (RuBERT + CLS тонкие головы + OOD)

Этот репозиторий содержит полностью рабочий прототип (near‑MVP) классификатора объявлений на русском языке. 
Решение построено на **RuBERT** для coarse‑классификации (верхний уровень), **тонких саб‑головах** для подкатегорий, 
**OOD‑детекции** по эмбеддингам CLS и **эвристиках** (hints/boost).

---

## Стек и зависимости

- **Python** 3.11+ (Local dev + Colab T4)
- **PyTorch**, **HuggingFace Transformers**
- **scikit‑learn** (CalibratedClassifierCV/LogReg и метрики)
- **NumPy / pandas**
- **Optuna** (калибровка порогов в исследовательских ноутбуках)


См. `pyproject.toml` и `poetry.lock` (или установку через `pip` — ниже).

---

## Архитектура решения

### 1) Coarse‑классификатор
- Модель: **RuBERT‑base** (HuggingFace). 
- Обучение на размеченных объявлениях; на выходе — метка coarse‑уровня и softmax‑уверенность.

### 2) OOD‑детекция (Out‑of‑Distribution)
- Признак: **L2‑норма** эмбеддинга **CLS** из RuBERT (после нормализации).
- Метод: оценка `z`‑скор через параметры `(mu, sigma)`; флаг OOD при `z > z_thr`.
- Параметры хранятся в `data/inference_thresholds.json` (см. ниже).

### 3) Sub‑головы (тонкие модели CLS)
- **Авто (марка)** — 20 классов.
- **Квартиры** — 10 классов (`аренда_1..4`, `продажа_1..4`, `студия_аренда/продажа`).
- Архитектура: **CalibratedClassifierCV / логистическая регрессия** на фиксированных **768‑d** эмбеддингах (RuBERT CLS).
- Плюсы: малая латентность, простое масштабирование под новые саб‑задачи, легкая поддержка.

### 4) Эвристики (A/B‑гипотезы)
- **Auto/Phone hints**: если в тексте явно присутствуют маркеры брендов (Kia, BMW, iPhone и т.д.), 
  допускается мягкий перекласс `Other -> целевой coarse` при низкой уверенности и легкий boost score (для витрины).

---

## Артефакты и расположение

```
data/
├─ rubert_cls_model/              # чекпойнт RuBERT coarse
├─ heads/
│  ├─ head_autos_brand.joblib     # тонкая голова: марки авто
│  └─ head_apart.joblib           # тонкая голова: квартиры
├─ cross_encoder_rubert/          # (опционально) cross‑encoder для rerank
├─ caches/                        # npy‑кэши эмбеддингов
├─ inference_thresholds.json      # пороги и параметры OOD/инференса
├─ supervised_*.csv / *.joblib    # отчеты/артефакты экспериментов
└─ synthetic_ru_private_ads_50cats_10000_v2.csv  # пример датасета
```

[Скачать артифакты](https://huggingface.co/NkvMax/ad-analyser-models/tree/main)

---

## Ключевые метрики (валидация)

Coarse‑классификация (RuBERT) на проверочной выборке:
- **Accuracy ≈ 0.993**
- **F1_macro ≈ 0.976**

Пороги и параметры инференса (из `data/inference_thresholds.json`):
```json
{
  "main_tau_other": 0.2825582677025756,
  "temperature": 0.91699954894511,
  "sub": {
    "autos_tau": 0.6,
    "apart_tau": 0.3
  },
  "ood": {
    "threshold": 4141.648698247054,
    "alpha": 1.49839657065949,
    "z_thr": 7.947675119608771,
    "mu": 863.1790571325726,
    "sigma": 675.8236249816604
  }
}
```
Эти значения используются в финальном пайплайне инференса и зафиксированы в отчетах `supervised_*`.

---

## Как запустить (локально)

### Вариант A · Poetry
```bash
poetry install --no-root
poetry run jupyter lab
```

### Вариант B · venv + pip
```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
python -m pip install -r requirements.txt
jupyter lab
```

Откройте ноутбук **`notebooks/05_Inference_Pipeline_Final.ipynb`** и выполните все ячейки. 
Финальные ячейки содержат:
- **chunk‑aware** инференс для длинных текстов;
- "витрину" предсказаний (аккуратная таблица);
- **mini‑UI (ipywidgets)** для ручных тестов.

---

## Как это работает в рантайме

1. **RuBERT** (coarse): для каждого текста формируется батч токенов; длинные тексты режутся на overlapped‑чанки. 
   На выходе — распределение по coarse‑классам и уверенность (с учетом `temperature`).
2. **Порог `main_tau_other`**: если уверенность ниже, метка переводится в **Other**.
3. **Эвристики**: при наличии **auto/phone hints** возможен мягкий перекласс и/или boost confidence.
4. **Sub‑головы**: если coarse in {Авто, Квартиры}, по CLS‑эмбеддингу вызываются тонкие головы с порогами `autos_tau` / `apart_tau`.
5. **OOD**: `z`‑скор по норме CLS; при `z > z_thr` выставляется флаг OOD (для офлайн‑фильтрации).

---

## Репродуцируемость

- Фиксированные `random_state=42` (в ноутбуках обучения и калибровки).
- **Пороги и OOD‑параметры** зафиксированы в `data/inference_thresholds.json` и применяются везде. 
- Для длительных ноутбуков (обучение/Optuna) есть **Appendix** с историческими экспериментами. 


---

## Что дальше (R&D)

- **Multitask / shared encoder** — совместная дообучаемая головная часть под coarse+sub, один проход модели.
- **Active learning** — досборка "спорных" кейсов по энтропии/разрыву для точечной разметки.
- **CE‑rerank по триггеру** — вызывать только при малом softmax‑margin; логировать выигрыш на ретроспективе.
- **Автотеги** — извлекать атрибуты (двигатель/метро/площадь) легкими детекторами поверх эмбеддингов.
- **A/B‑доставка** — конфиги порогов/эвристик через feature‑flags (env/JSON).

---

## Лицензия и данные

- Код и скрипты — MIT
- Синтетические примеры включены для воспроизводимости пайплайна.


